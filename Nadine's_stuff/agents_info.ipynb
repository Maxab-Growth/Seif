{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981fdf02-054d-4dbe-aabe-b8dc55191c93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Old script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c15c0-55f2-4e37-a46c-f349a1da228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import importlib\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta, date\n",
    "import time\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "import gspread\n",
    "import sys\n",
    "import gzip\n",
    "import http.client\n",
    "import sqlalchemy\n",
    "import os\n",
    "import math\n",
    "import snowflake.connector\n",
    "\n",
    "# get secret function:\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            raise e\n",
    "    else:\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "\n",
    "\n",
    "def get_from_gsheet_edited(workbook, sheet):\n",
    "    scope = [\n",
    "        \"https://spreadsheets.google.com/feeds\",\n",
    "        'https://www.googleapis.com/auth/spreadsheets',\n",
    "        \"https://www.googleapis.com/auth/drive.file\",\n",
    "        \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "    json_path2 = \"/tmp//maxab_sheets_key.json\"\n",
    "    print(json_path2)\n",
    "    maxab_sheets_key = get_secret(\"prod/maxab-sheets\")\n",
    "    f = open(json_path2, \"w\")\n",
    "    f.write(maxab_sheets_key)\n",
    "    f.close()\n",
    "    os.environ[\"MAXAB_SHEETS_KEY_PATH\"] = json_path2\n",
    "\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(os.environ[\"MAXAB_SHEETS_KEY_PATH\"], scope)\n",
    "    client = gspread.authorize(creds)\n",
    "\n",
    "    wks = client.open(workbook).worksheet(sheet)\n",
    "    sheet = pd.DataFrame(wks.get_all_values())\n",
    "    sheet.columns = sheet.iloc[0]\n",
    "    sheet = sheet[1:]\n",
    "    sheet = sheet[sheet.columns[list(map(lambda x: x != '', sheet.columns))]]\n",
    "    return sheet\n",
    "\n",
    "\n",
    "def send_custom_events(custom_events):\n",
    "    try:\n",
    "        base_url = 'https://go.urbanairship.com'\n",
    "        base_headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': 'Bearer ' + os.environ[\"AIRSHIP_ACCESS_TOKEN\"],\n",
    "            'X-UA-Appkey': os.environ[\"AIRSHIP_APP_KEY\"],\n",
    "            'Accept': 'application/vnd.urbanairship+json; version=3'\n",
    "        }\n",
    "        s_response = requests.post(\n",
    "            base_url + '/api/custom-events',\n",
    "            data=json.dumps(custom_events),\n",
    "            headers=base_headers\n",
    "        )\n",
    "        s_response.raise_for_status()\n",
    "\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(err)\n",
    "\n",
    "\n",
    "def send_custom_events_lite(custom_events):\n",
    "    try:\n",
    "        base_url = 'https://go.urbanairship.com'\n",
    "        base_headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': 'Bearer '+os.environ[\"AIRSHIP_ACCESS_TOKEN_LITE\"],\n",
    "            'X-UA-Appkey': os.environ[\"AIRSHIP_APP_KEY_LITE\"],\n",
    "            'Accept': 'application/vnd.urbanairship+json; version=3'\n",
    "        }\n",
    "        s_response = requests.post(\n",
    "            base_url + '/api/custom-events',\n",
    "            data=json.dumps(custom_events),\n",
    "            headers=base_headers\n",
    "        )\n",
    "        s_response.raise_for_status()\n",
    "\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(err)\n",
    "\n",
    "\n",
    "def tag_airship_users(user_tags):\n",
    "    try:\n",
    "        base_url = 'https://go.urbanairship.com'\n",
    "        base_headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': 'Bearer ' + os.environ[\"AIRSHIP_ACCESS_TOKEN\"],\n",
    "            'X-UA-Appkey': os.environ[\"AIRSHIP_APP_KEY\"],\n",
    "            'Accept': 'application/vnd.urbanairship+json; version=3'\n",
    "        }\n",
    "        s_response = requests.post(\n",
    "            base_url + '/api/named_users/tags',\n",
    "            data=json.dumps(user_tags),\n",
    "            headers=base_headers\n",
    "        )\n",
    "        s_response.raise_for_status()\n",
    "\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(err)\n",
    "\n",
    "\n",
    "def build_custom_event(event_properties, main_system_id, event_name):\n",
    "    named_user = \"EG_retailers_\" + str(main_system_id)\n",
    "    # named_user =  \"EG_retailers_{}\".format(main_system_id)\n",
    "    retailer_event = {}\n",
    "    retailer_event['occurred'] = str(datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"))\n",
    "    retailer_event['user'] = {\"named_user_id\": str(named_user)}\n",
    "\n",
    "    retailer_event['body'] = {\"name\": event_name, \"properties\": event_properties}\n",
    "\n",
    "    return retailer_event\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # dwh connection:\n",
    "    dwh_reader_secret_new = json.loads(get_secret(\"prod/db/datawarehouse/metabase\"))\n",
    "\n",
    "    dwh_writer_secret_new = json.loads(get_secret(\"prod/db/datawarehouse/sagemaker\"))\n",
    "    host=dwh_reader_secret_new[\"host\"]\n",
    "    database=dwh_reader_secret_new[\"dbname\"]\n",
    "    user=dwh_reader_secret_new[\"username\"]\n",
    "    password=dwh_reader_secret_new[\"password\"]\n",
    "\n",
    "    conn = psycopg2.connect(host=host, database=database, user=user, password=password)\n",
    "    print(\"Successfully connected to DB\")\n",
    "\n",
    "    # snowflake connection:\n",
    "    snowflake_secret = json.loads(get_secret(\"prod/snowflake/fintech-credentials\"))\n",
    "    sf_account = snowflake_secret[\"snowflake_account\"]\n",
    "    sf_warehouse = snowflake_secret[\"snowflake_fintech_warehouse\"]\n",
    "    sf_database = snowflake_secret[\"snowflake_database\"]\n",
    "    sf_username = snowflake_secret[\"snowflake_fintech_username\"]\n",
    "    sf_password = snowflake_secret[\"snowflake_fintech_password\"]\n",
    "\n",
    "    snowflake_con = snowflake.connector.connect(\n",
    "        user=sf_username,\n",
    "        account=sf_account,\n",
    "        password=sf_password,\n",
    "        database=sf_database,\n",
    "        warehouse=sf_warehouse\n",
    "    )\n",
    "\n",
    "    # airship connection:\n",
    "    airship_secret = json.loads(get_secret(\"prod/airship/accessToken\"))\n",
    "\n",
    "    os.environ[\"AIRSHIP_APP_KEY\"] = airship_secret['AIRSHIP_APP_KEY']\n",
    "    os.environ[\"AIRSHIP_ACCESS_TOKEN\"] = airship_secret['AIRSHIP_ACCESS_TOKEN']\n",
    "\n",
    "    # airship connection lite version:\n",
    "\n",
    "    airship_secret = json.loads(get_secret(\"prod/airship/accessToken/lite\"))\n",
    "\n",
    "    os.environ[\"AIRSHIP_APP_KEY_LITE\"] = airship_secret['AIRSHIP_APP_KEY_LITE']\n",
    "    os.environ[\"AIRSHIP_ACCESS_TOKEN_LITE\"] = airship_secret['AIRSHIP_ACCESS_TOKEN_LITE']\n",
    "\n",
    "    # get drivers sheet data:\n",
    "    collection_agents_personal_info = get_from_gsheet_edited(\"collection_agents_personal_info\", \"Sheet1\")\n",
    "\n",
    "    # getting records:\n",
    "    for record in event['Records']:\n",
    "        data = record['dynamodb']['NewImage']\n",
    "        print(data)\n",
    "        print(event)\n",
    "\n",
    "        for key in list(data.keys()):\n",
    "            if key in [\n",
    "                'retailer_id',\n",
    "                'collection_order_status_id',\n",
    "                'collection_amount',\n",
    "                'collected_amount',\n",
    "                'created_at',\n",
    "                'updated_at',\n",
    "                'initial_date',\n",
    "                'cashin_mode_id',\n",
    "                'id'\n",
    "            ]:\n",
    "                data[key] = list(data[key].values())[0]\n",
    "            else:\n",
    "                del data[key]\n",
    "\n",
    "        print(data)\n",
    "        # get collection order id:\n",
    "\n",
    "        collection_order_status_id = data['collection_order_status_id']\n",
    "        collection_order_id = data['id']\n",
    "        main_system_id = data['retailer_id']\n",
    "\n",
    "        # get agent information:\n",
    "        agent_mobile_query = '''select\n",
    "            national_id,\n",
    "            mobile,\n",
    "            name,\n",
    "            drivers.id,\n",
    "            split_part(name,' ',1) first_name,\n",
    "            split_part(name,' ',2) last_name,\n",
    "            right(national_id,7) as last_7_national_id\n",
    "        from public.drivers\n",
    "            join public.run_sheets on run_sheets.driver_id = drivers.id \n",
    "            join public.collection_orders on collection_orders.run_sheet_id = run_sheets.id\n",
    "\n",
    "        where collection_orders.id={} '''.format(collection_order_id)\n",
    "\n",
    "        try:\n",
    "            agent_mobile_query_result = pd.read_sql(agent_mobile_query, conn)\n",
    "\n",
    "            # agent_first_name = agent_mobile_query_result.loc[0,'first_name']\n",
    "            # agent_last_name= agent_mobile_query_result.loc[0,'last_name']\n",
    "\n",
    "            agent_last_7_digits_nid = agent_mobile_query_result.loc[0, 'last_7_national_id']\n",
    "            agent_nid = agent_mobile_query_result.loc[0, 'national_id']\n",
    "            agent_full_name_ar = collection_agents_personal_info.loc[collection_agents_personal_info.national_id==agent_nid, 'name_ar'].values.tolist()[0]\n",
    "            agent_first_name_ar = agent_full_name_ar.split(\" \")[0]\n",
    "            agent_second_name_ar = agent_full_name_ar.split(\" \")[1]\n",
    "            agent_third_name_ar = agent_full_name_ar.split(\" \")[2]\n",
    "            agent_mobile = agent_mobile_query_result.loc[0, 'mobile']\n",
    "            agent_id = str(agent_mobile_query_result.loc[0, 'id'])\n",
    "\n",
    "            # add variables to the trigger:\n",
    "            data['agent_id'] = agent_id\n",
    "            data['agent_mobile'] = agent_mobile\n",
    "            data['agent_last_7_digits_nid'] = agent_last_7_digits_nid\n",
    "            data['agent_first_name_ar'] = agent_first_name_ar\n",
    "            data['agent_second_name_ar'] = agent_second_name_ar\n",
    "            data['agent_third_name_ar'] = agent_third_name_ar\n",
    "\n",
    "            print(data)\n",
    "            # create the trigger:\n",
    "            custom_event = build_custom_event(data, main_system_id, \"db_trigger_collection_order\")\n",
    "\n",
    "            # send the trigger to airship:\n",
    "            send_custom_events(custom_event)\n",
    "\n",
    "            # send the trigger to airship lite version:\n",
    "            send_custom_events_lite(custom_event)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('Hello from Lambda!')\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844ac24-d87d-456e-9113-5a7a54b74fdb",
   "metadata": {},
   "source": [
    "## New script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8e7434-57a2-4ed5-af85-b0cb2e5774a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import http.client\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import re \n",
    "# import snowflake.connector\n",
    "from datetime import datetime\n",
    "\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "dynamodb_table = dynamodb.Table('db_trigger')\n",
    "\n",
    "# sending sms:\n",
    "def send_message(messagesObject, tag=None):\n",
    "    auth = \"App b9c03ee856baa2b7ac96b4b0ecb8aa36-ce2dbf98-1fd2-4fff-9b8b-0d5b8187c834\"\n",
    "    conn = http.client.HTTPSConnection(\"qg3p63.api.infobip.com\")\n",
    "    if tag is None:\n",
    "        payload = json.dumps({\"messages\": messagesObject})\n",
    "    else:\n",
    "        payload = json.dumps({\"bulkId\": tag, \"messages\": messagesObject})\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': \"App b9c03ee856baa2b7ac96b4b0ecb8aa36-ce2dbf98-1fd2-4fff-9b8b-0d5b8187c834\",\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    conn.request(\"POST\", \"/sms/2/text/advanced\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    final = eval(data)\n",
    "    print(data)\n",
    "    print(final['bulkId'])\n",
    "\n",
    "    return final['bulkId']\n",
    "    \n",
    "# get secret function:\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            raise e\n",
    "    else:\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary']) \n",
    "\n",
    "# get message result:\n",
    "# get message result:\n",
    "def get_sms_results(bulkId=None, messageId=None, after_timestamp=None):\n",
    "    # Authentication\n",
    "    conn = http.client.HTTPSConnection(\"qg3p63.api.infobip.com\")\n",
    "    payload = ''\n",
    "    headers = {\n",
    "        'Authorization': 'App b9c03ee856baa2b7ac96b4b0ecb8aa36-ce2dbf98-1fd2-4fff-9b8b-0d5b8187c834',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    # Get reports based on messageId:\n",
    "    if messageId:\n",
    "        # Connect with the API and get the response based on bulkId:\n",
    "        conn.request(\"GET\", \"/sms/1/logs?messageId={}\".format(messageId), payload, headers)\n",
    "        res = conn.getresponse()\n",
    "        data = res.read()\n",
    "        d = json.loads(data)\n",
    "        df = pd.DataFrame(d['results'])\n",
    "        new_col_names = [\n",
    "            'bulk_id',\n",
    "            'message_id',\n",
    "            'to',\n",
    "            'from',\n",
    "            'text',\n",
    "            'sent_at',\n",
    "            'done_at',\n",
    "            'sms_count',\n",
    "            'price',\n",
    "            'status',\n",
    "            'error',\n",
    "            'application_id'\n",
    "        ]\n",
    "\n",
    "        \n",
    "        try:\n",
    "            # drop mccMnc:\n",
    "            df.drop(columns=['mccMnc'], inplace=True)\n",
    "\n",
    "            # drop the country code (2):\n",
    "            df.to = df.to.str[1:]\n",
    "            \n",
    "            # change columns names:\n",
    "            df.columns = new_col_names\n",
    "            \n",
    "            # data wrangling:\n",
    "            # error column cleaning\n",
    "            df['error'] = df['error'].apply(lambda x: x['name'])\n",
    "\n",
    "            # status:\n",
    "            df['status'] = df['status'].apply(lambda x: x['groupName'])\n",
    "\n",
    "            # price:\n",
    "            df['price'] = df['price'].apply(lambda x: x['pricePerMessage'])\n",
    "\n",
    "            # dates cleaning:\n",
    "            df['sentAt'] = pd.to_datetime(df['sentAt'], format='%Y-%m-%dT%H:%M:%S').apply(lambda x: x.replace(tzinfo=None))\n",
    "            df['doneAt'] = pd.to_datetime(df['doneAt'], format='%Y-%m-%dT%H:%M:%S').apply(lambda x: x.replace(tzinfo=None))\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('error e'.format(e))\n",
    "\n",
    "    # Get reports base on bulkId:\n",
    "    elif bulkId:\n",
    "        # Connect with the API and get the response based on bulkId:\n",
    "        conn.request(\"GET\", \"/sms/1/logs?bulkId={}\".format(bulkId), payload, headers)\n",
    "        res = conn.getresponse()\n",
    "        data = res.read()\n",
    "        d = json.loads(data)\n",
    "        df = pd.DataFrame(d['results'])\n",
    "        new_col_names = [\n",
    "            'bulk_id',\n",
    "            'message_id',\n",
    "            'to',\n",
    "            'from',\n",
    "            'text',\n",
    "            'sent_at',\n",
    "            'done_at',\n",
    "            'sms_count',\n",
    "            'price',\n",
    "            'status',\n",
    "            'error',\n",
    "            'application_id'\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # drop mccMnc:\n",
    "            df.drop(columns=['mccMnc'], inplace=True)\n",
    "\n",
    "            # drop the country code (2):\n",
    "            df.to = df.to.str[1:]\n",
    "            \n",
    "            # change columns names:\n",
    "            df.columns = new_col_names\n",
    "            \n",
    "            # data wrangling:\n",
    "            # error column cleaning:\n",
    "            df['error'] = df['error'].apply(lambda x: x['name'])\n",
    "\n",
    "            # status:\n",
    "            df['status'] = df['status'].apply(lambda x: x['groupName'])\n",
    "\n",
    "            # price:\n",
    "            df['price'] = df['price'].apply(lambda x: x['pricePerMessage'])\n",
    "\n",
    "            # dates cleaning:\n",
    "            df['sentAt'] = pd.to_datetime(df['sentAt'], format='%Y-%m-%dT%H:%M:%S.%f%z').apply(lambda x: x.replace(tzinfo=None))\n",
    "            df['doneAt'] = pd.to_datetime(df['doneAt'], format='%Y-%m-%dT%H:%M:%S.%f%z').apply(lambda x: x.replace(tzinfo=None))\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('error {}'.format(e))\n",
    "\n",
    "    else:\n",
    "        return print(\"error in inputs\")\n",
    "\n",
    "    if after_timestamp:\n",
    "        after_timestamp = datetime.datetime.strptime(after_timestamp, '%Y-%m-%d %H:%M:%S.%f')\n",
    "        df_subset = df.loc[df.sent_at >= after_timestamp]\n",
    "\n",
    "    else:\n",
    "        df_subset = df\n",
    "\n",
    "    return df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e2e84b-d577-448d-9a64-dc88e7d1e5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lambda_handler(event):\n",
    "    \n",
    "    # connect to the dwh db:\n",
    "    dwh_reader_secret_new = json.loads(get_secret(\"prod/db/datawarehouse/metabase\"))\n",
    "    dwh_writer_secret_new = json.loads(get_secret(\"prod/db/datawarehouse/sagemaker\"))\n",
    "\n",
    "    # get secrets: -dwh reader\n",
    "    host_r=dwh_reader_secret_new[\"host\"]\n",
    "    database_r=dwh_reader_secret_new[\"dbname\"]\n",
    "    user_r=dwh_reader_secret_new[\"username\"]\n",
    "    password_r=dwh_reader_secret_new[\"password\"]\n",
    "    \n",
    "    # get secrets: -dwh writer\n",
    "    host_w=dwh_writer_secret_new[\"host\"]\n",
    "    database_w=dwh_writer_secret_new[\"dbname\"]\n",
    "    user_w=dwh_writer_secret_new[\"username\"]\n",
    "    password_w=dwh_writer_secret_new[\"password\"]\n",
    "\n",
    "    conn_r = psycopg2.connect(host=host_r, database=database_r, user=user_r, password=password_r)\n",
    "    print(\"Successfully connected to reader DB\")\n",
    "    \n",
    "    conn_w = psycopg2.connect(host=host_w, database=database_w, user=user_w, password=password_w)\n",
    "    print(\"Successfully connected to writer DB\")\n",
    "    \n",
    "        \n",
    "#     # check if there is a need for the message:\n",
    "#     try:\n",
    "#         linked_at_id, retailer_id, linked_device_id, device_type, device_manufacturer, mobile  = get_inputs_from_event(event, conn_r)\n",
    "#         # get_inputs_from_event(event,conn_r)\n",
    "#     except Exception as e:\n",
    "#         print(\"error in getting full_result:{}\".format(e))\n",
    "#         check_validity = get_inputs_from_event(event, conn_r)\n",
    "    \n",
    "    valid_records_list=[]\n",
    "    for record in event['Records']:\n",
    "        data = record['dynamodb']['NewImage']\n",
    "        print(data) \n",
    "        print(event)\n",
    "        \n",
    "        #extract relevant data \n",
    "        collection_order_id = list(data['id'].values())[0]\n",
    "        updated_at = list(data['updated_at'].values())[0]\n",
    "        collection_order_updated_at = datetime.strptime(updated_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        collection_order_updated_at = collection_order_updated_at.date()\n",
    "        retailer_id =  list(data['retailer_id'].values())[0]\n",
    "        run_sheet_id = list(data['run_sheet_id'].values())[0]\n",
    "    \n",
    "        if(collection_order_updated_at != datetime.today().date()):\n",
    "\n",
    "            print('collection order wasnt updated today')\n",
    "            continue \n",
    "\n",
    "        #get the retailer mobile number \n",
    "\n",
    "        get_mobile_sql = '''\n",
    "        select distinct r.retailer_id , r.mobile \n",
    "        from public.retailers r\n",
    "        where r.id = {}\n",
    "        '''.format(retailer_id)\n",
    "\n",
    "        get_mobile_sql_result = pd.read_sql(get_mobile_sql, conn_r)\n",
    "        main_system_id = get_mobile_sql_result['retailer_id'][0]\n",
    "        mobile = get_mobile_sql_result['mobile'][0]\n",
    "        \n",
    "#     print(linked_at_id, linked_at, retailer_id, linked_device_id,mobile,main_system_id,device_type,device_manufacturer )\n",
    "  \n",
    "\n",
    "#     #check if there is a need to send the sms \n",
    "#     #check comms rules:\n",
    "#     check_comm_counter_sql = '''\n",
    "#      select distinct\n",
    "#         receiver_id,\n",
    "#         ref_entity,\n",
    "#         ref_id,\n",
    "#         receiver_phone,\n",
    "#         date(cast(sending_time as date)) as sending_date,\n",
    "#         count(case when message_status in ('PENDING','DELIVERED') then 1 else null end) over(partition by receiver_id, date_trunc('day',cast(sending_time as date))) as successful_sms_per_day,\n",
    "#         count(*) over(partition by receiver_id, date_trunc('day',cast(sending_time as date))) as sms_per_day,\n",
    "#         count(case when message_status in ('PENDING','DELIVERED') then 1 else null end) over(partition by receiver_id,ref_entity, ref_id) as successful_sms_per_entity_per_ref_id,\n",
    "#         count(*) over(partition by receiver_id,ref_entity, ref_id) as sms_per_entity_per_ref_id\n",
    "#     from fintech.fintech_communication_logs\n",
    "#     where ref_entity = 'device_linked_at_id'\n",
    "#         and communication_reason = 'new_device_notification_test'\n",
    "#         and date(sending_time) = date(now()) \n",
    "#         and ref_id = {}'''.format(linked_at_id)\n",
    "\n",
    "#     try:\n",
    "#         check_comm_counter_sql_result = pd.read_sql(check_comm_counter_sql, conn_r)\n",
    "#         successful_sms_per_entity_per_ref_id = check_comm_counter_sql_result['successful_sms_per_entity_per_ref_id'][0]\n",
    "#     except Exception as e:\n",
    "#         print(\"error in comm counter result:{}\".format(e))\n",
    "#         successful_sms_per_entity_per_ref_id = 0\n",
    "\n",
    "#     if successful_sms_per_entity_per_ref_id >= 1:\n",
    "#         print(\"message has already been sent\")\n",
    "#         return \"max_comm_validation\"\n",
    "\n",
    "    \n",
    "#     # Send SMS:\n",
    "    \n",
    "#     # generate message object:\n",
    "# #     receiver_mobile = \"2\"+mobile\n",
    "#     receiver_mobile = \"201112255939\"\n",
    "\n",
    "#     if device_type == 'MOBILE':\n",
    "        \n",
    "#         sms_template = 'عميل مدفوعات، تم اضافة جهاز جديد {0} لحسابك. في حالة عدم الموافقة يرجى التواصل معنا على 15425 في اسرع وقت'\n",
    "#         y = [{\n",
    "#             'from':'MaxAB',\n",
    "#             'destinations': [{\"to\": \"{}\".format(receiver_mobile)}], 'text': sms_template.format(device_manufacturer)}]\n",
    "    \n",
    "#     else: \n",
    "        \n",
    "#         sms_template = 'عميل مدفوعات، تم اضافة ماكينة جديدة لحسابك. في حالة عدم الموافقة يرجى التواصل معنا على 15425 في اسرع وقت'\n",
    "#         y = [{\n",
    "#             'from':'MaxAB',\n",
    "#             'destinations': [{\"to\": \"{}\".format(receiver_mobile)}], 'text': sms_template}]\n",
    "\n",
    "#     message_tag = \"new_device_notification_{}\".format(linked_at_id)\n",
    "\n",
    "#     send_message(y, tag=message_tag)\n",
    "#     print('message_sent_to_{}'.format(linked_at_id))\n",
    "#     time.sleep(20)\n",
    "\n",
    "#     # get message result:\n",
    "#     message_result = get_sms_results(bulkId=message_tag)\n",
    "#     print(message_result)\n",
    "\n",
    "#     try:\n",
    "#         message_id = message_result[message_result.bulk_id == message_tag]['message_id'][0]\n",
    "#     except:\n",
    "#         message_id = 0\n",
    "#     try:\n",
    "#         sending_time = message_result[message_result.bulk_id == message_tag]['sent_at'][0]\n",
    "#     except:\n",
    "#         sending_time = datetime.now()\n",
    "#     try:\n",
    "#         message_status = message_result[message_result.bulk_id == message_tag]['status'][0]\n",
    "#     except:\n",
    "#         message_status = 'Unkown'\n",
    "\n",
    "\n",
    "#     # Write SMS Logs to DB \n",
    "#     # db connection:\n",
    "    \n",
    "#     engine_w = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user_w}:{password_w}@{host_w}/{database_w}\")\n",
    "#     print(bool(engine_w))\n",
    "    \n",
    "#     with engine_w.connect() as conn:\n",
    "#         print(\"start writing into fintech sms logs table\")\n",
    "#         message_result.to_sql(name='fintech_sms_logs', schema='fintech', con=conn, if_exists='append', chunksize=1000, method='multi')\n",
    "#         print(\"written into fintech sms logs table successfully\")\n",
    "\n",
    "#     # push comm log to db\n",
    "#     comm_df = pd.DataFrame(columns=[\n",
    "#         'receiver_type',\n",
    "#         'receiver_id',\n",
    "#         'receiver_phone',\n",
    "#         'communication_reason',\n",
    "#         'ref_id',\n",
    "#         'ref_entity',\n",
    "#         'message_id',\n",
    "#         'message_status',\n",
    "#         'sending_time'])\n",
    "\n",
    "#     comm_df.loc[len(comm_df)] = [\n",
    "#         'retailer',\n",
    "#         main_system_id,\n",
    "#         mobile,\n",
    "#         'new_device_notification_test',\n",
    "#         linked_at_id,\n",
    "#         'device_linked_at_id',\n",
    "#         message_id,\n",
    "#         message_status,\n",
    "#         sending_time]\n",
    "\n",
    "#     # update the table on db:\n",
    "#     with engine_w.connect() as conn:\n",
    "#         print(\"start writing into fintech communication logs table\")\n",
    "#         comm_df.to_sql(\n",
    "#             name='fintech_communication_logs',\n",
    "#             schema='fintech',\n",
    "#             con=conn,\n",
    "#             if_exists='append',\n",
    "#             chunksize=1000,\n",
    "#             method='multi')\n",
    "#         print(\"written into fintech communication logs table successfully\")\n",
    "\n",
    "\n",
    "\n",
    "#     # close the connection:\n",
    "#     conn_w.close()\n",
    "#     conn_r.close()\n",
    "\n",
    "#     return {\n",
    "#         'statusCode': 200,\n",
    "#         'body': json.dumps('Hello from Lambda!')\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36cb50b9-7de8-4073-98fe-ed3d902e1dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to reader DB\n",
      "Successfully connected to writer DB\n",
      "{'date': {'S': '2024-05-29T00:00:00Z'}, 'is_partial': {'NULL': True}, 'collection_order_status_id': {'N': '3'}, 'cashin_mode_id': {'N': '2'}, 'created_at': {'S': '2024-05-28T01:55:05Z'}, 'run_sheet_id': {'N': '1402353'}, 'locus_rank': {'NULL': True}, 'collection_order_ttl': {'N': '1716947705'}, 'updated_at': {'S': '2024-05-29T14:40:10Z'}, 'confirmation_counter': {'N': '0'}, 'collection_amount': {'N': '1000'}, 'initial_date': {'S': '2024-05-29T00:00:00Z'}, 'minimum_collection_amount': {'NULL': True}, 'id': {'N': '118562018'}, 'collected_amount': {'N': '0'}, 'type_id': {'N': '2'}, 'num_of_delays': {'N': '0'}, 'collections_order_sub_status_id': {'N': '1'}, 'retailer_id': {'N': '287674'}, 'submitted_by': {'S': 'RETAILER'}, 'maximum_collection_amount': {'NULL': True}, 'vehicle_type_id': {'N': '34'}, 'issued_collection_amount': {'N': '1000'}, 'maxab_collection_order_id': {'N': '2997886'}, 'district_id': {'N': '565'}, 'amount_to_be_collected': {'NULL': True}, 'category_group_id': {'N': '1'}, 'tag_english': {'S': 'Cash-in Request'}, 'warehouse_id': {'N': '1'}}\n",
      "{'Records': [{'eventID': '20af2fd73916b0c9c7af91236a92538c', 'eventName': 'MODIFY', 'eventVersion': '1.1', 'eventSource': 'aws:dynamodb', 'awsRegion': 'us-east-1', 'dynamodb': {'ApproximateCreationDateTime': 1716982811.0, 'Keys': {'id': {'N': '118562018'}}, 'NewImage': {'date': {'S': '2024-05-29T00:00:00Z'}, 'is_partial': {'NULL': True}, 'collection_order_status_id': {'N': '3'}, 'cashin_mode_id': {'N': '2'}, 'created_at': {'S': '2024-05-28T01:55:05Z'}, 'run_sheet_id': {'N': '1402353'}, 'locus_rank': {'NULL': True}, 'collection_order_ttl': {'N': '1716947705'}, 'updated_at': {'S': '2024-05-29T14:40:10Z'}, 'confirmation_counter': {'N': '0'}, 'collection_amount': {'N': '1000'}, 'initial_date': {'S': '2024-05-29T00:00:00Z'}, 'minimum_collection_amount': {'NULL': True}, 'id': {'N': '118562018'}, 'collected_amount': {'N': '0'}, 'type_id': {'N': '2'}, 'num_of_delays': {'N': '0'}, 'collections_order_sub_status_id': {'N': '1'}, 'retailer_id': {'N': '287674'}, 'submitted_by': {'S': 'RETAILER'}, 'maximum_collection_amount': {'NULL': True}, 'vehicle_type_id': {'N': '34'}, 'issued_collection_amount': {'N': '1000'}, 'maxab_collection_order_id': {'N': '2997886'}, 'district_id': {'N': '565'}, 'amount_to_be_collected': {'NULL': True}, 'category_group_id': {'N': '1'}, 'tag_english': {'S': 'Cash-in Request'}, 'warehouse_id': {'N': '1'}}, 'OldImage': {'date': {'S': '2024-05-29T00:00:00Z'}, 'type_id': {'N': '2'}, 'collection_order_status_id': {'N': '1'}, 'num_of_delays': {'N': '0'}, 'cashin_mode_id': {'N': '2'}, 'collections_order_sub_status_id': {'N': '3'}, 'created_at': {'S': '2024-05-28T01:55:05Z'}, 'retailer_id': {'N': '287674'}, 'submitted_by': {'S': 'RETAILER'}, 'collection_order_ttl': {'N': '1716947705'}, 'vehicle_type_id': {'N': '34'}, 'updated_at': {'S': '2024-05-28T01:55:05Z'}, 'confirmation_counter': {'N': '0'}, 'collection_amount': {'N': '1000'}, 'initial_date': {'S': '2024-05-29T00:00:00Z'}, 'issued_collection_amount': {'N': '1000'}, 'maxab_collection_order_id': {'N': '2997886'}, 'district_id': {'N': '565'}, 'id': {'N': '118562018'}, 'category_group_id': {'N': '1'}, 'tag_english': {'S': 'Cash-in Request'}, 'collected_amount': {'N': '0'}, 'warehouse_id': {'N': '1'}}, 'SequenceNumber': '571610300000000091106732594', 'SizeBytes': 1098, 'StreamViewType': 'NEW_AND_OLD_IMAGES'}, 'eventSourceARN': 'arn:aws:dynamodb:us-east-1:876425898567:table/collection_orders/stream/2024-05-29T11:14:01.243'}]}\n",
      "collection order wasnt updated today\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'collection order wasnt updated today'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_handler(\n",
    "{\n",
    "   \"Records\":[\n",
    "      {\n",
    "         \"eventID\":\"20af2fd73916b0c9c7af91236a92538c\",\n",
    "         \"eventName\":\"MODIFY\",\n",
    "         \"eventVersion\":\"1.1\",\n",
    "         \"eventSource\":\"aws:dynamodb\",\n",
    "         \"awsRegion\":\"us-east-1\",\n",
    "         \"dynamodb\":{\n",
    "            \"ApproximateCreationDateTime\":1716982811.0,\n",
    "            \"Keys\":{\n",
    "               \"id\":{\n",
    "                  \"N\":\"118562018\"\n",
    "               }\n",
    "            },\n",
    "            \"NewImage\":{\n",
    "               \"date\":{\n",
    "                  \"S\":\"2024-05-29T00:00:00Z\"\n",
    "               },\n",
    "               \"is_partial\":{\n",
    "                  \"NULL\":True\n",
    "               },\n",
    "               \"collection_order_status_id\":{\n",
    "                  \"N\":\"3\"\n",
    "               },\n",
    "               \"cashin_mode_id\":{\n",
    "                  \"N\":\"2\"\n",
    "               },\n",
    "               \"created_at\":{\n",
    "                  \"S\":\"2024-05-28T01:55:05Z\"\n",
    "               },\n",
    "               \"run_sheet_id\":{\n",
    "                  \"N\":\"1402353\"\n",
    "               },\n",
    "               \"locus_rank\":{\n",
    "                  \"NULL\":True\n",
    "               },\n",
    "               \"collection_order_ttl\":{\n",
    "                  \"N\":\"1716947705\"\n",
    "               },\n",
    "               \"updated_at\":{\n",
    "                  \"S\":\"2024-05-29T14:40:10Z\"\n",
    "               },\n",
    "               \"confirmation_counter\":{\n",
    "                  \"N\":\"0\"\n",
    "               },\n",
    "               \"collection_amount\":{\n",
    "                  \"N\":\"1000\"\n",
    "               },\n",
    "               \"initial_date\":{\n",
    "                  \"S\":\"2024-05-29T00:00:00Z\"\n",
    "               },\n",
    "               \"minimum_collection_amount\":{\n",
    "                  \"NULL\":True\n",
    "               },\n",
    "               \"id\":{\n",
    "                  \"N\":\"118562018\"\n",
    "               },\n",
    "               \"collected_amount\":{\n",
    "                  \"N\":\"0\"\n",
    "               },\n",
    "               \"type_id\":{\n",
    "                  \"N\":\"2\"\n",
    "               },\n",
    "               \"num_of_delays\":{\n",
    "                  \"N\":\"0\"\n",
    "               },\n",
    "               \"collections_order_sub_status_id\":{\n",
    "                  \"N\":\"1\"\n",
    "               },\n",
    "               \"retailer_id\":{\n",
    "                  \"N\":\"287674\"\n",
    "               },\n",
    "               \"submitted_by\":{\n",
    "                  \"S\":\"RETAILER\"\n",
    "               },\n",
    "               \"maximum_collection_amount\":{\n",
    "                  \"NULL\":True\n",
    "               },\n",
    "               \"vehicle_type_id\":{\n",
    "                  \"N\":\"34\"\n",
    "               },\n",
    "               \"issued_collection_amount\":{\n",
    "                  \"N\":\"1000\"\n",
    "               },\n",
    "               \"maxab_collection_order_id\":{\n",
    "                  \"N\":\"2997886\"\n",
    "               },\n",
    "               \"district_id\":{\n",
    "                  \"N\":\"565\"\n",
    "               },\n",
    "               \"amount_to_be_collected\":{\n",
    "                  \"NULL\":True\n",
    "               },\n",
    "               \"category_group_id\":{\n",
    "                  \"N\":\"1\"\n",
    "               },\n",
    "               \"tag_english\":{\n",
    "                  \"S\":\"Cash-in Request\"\n",
    "               },\n",
    "               \"warehouse_id\":{\n",
    "                  \"N\":\"1\"\n",
    "               }\n",
    "            },\n",
    "            \"OldImage\":{\n",
    "               \"date\":{\n",
    "                  \"S\":\"2024-05-29T00:00:00Z\"\n",
    "               },\n",
    "               \"type_id\":{\n",
    "                  \"N\":\"2\"\n",
    "               },\n",
    "               \"collection_order_status_id\":{\n",
    "                  \"N\":\"1\"\n",
    "               },\n",
    "               \"num_of_delays\":{\n",
    "                  \"N\":\"0\"\n",
    "               },\n",
    "               \"cashin_mode_id\":{\n",
    "                  \"N\":\"2\"\n",
    "               },\n",
    "               \"collections_order_sub_status_id\":{\n",
    "                  \"N\":\"3\"\n",
    "               },\n",
    "               \"created_at\":{\n",
    "                  \"S\":\"2024-05-28T01:55:05Z\"\n",
    "               },\n",
    "               \"retailer_id\":{\n",
    "                  \"N\":\"287674\"\n",
    "               },\n",
    "               \"submitted_by\":{\n",
    "                  \"S\":\"RETAILER\"\n",
    "               },\n",
    "               \"collection_order_ttl\":{\n",
    "                  \"N\":\"1716947705\"\n",
    "               },\n",
    "               \"vehicle_type_id\":{\n",
    "                  \"N\":\"34\"\n",
    "               },\n",
    "               \"updated_at\":{\n",
    "                  \"S\":\"2024-05-28T01:55:05Z\"\n",
    "               },\n",
    "               \"confirmation_counter\":{\n",
    "                  \"N\":\"0\"\n",
    "               },\n",
    "               \"collection_amount\":{\n",
    "                  \"N\":\"1000\"\n",
    "               },\n",
    "               \"initial_date\":{\n",
    "                  \"S\":\"2024-05-29T00:00:00Z\"\n",
    "               },\n",
    "               \"issued_collection_amount\":{\n",
    "                  \"N\":\"1000\"\n",
    "               },\n",
    "               \"maxab_collection_order_id\":{\n",
    "                  \"N\":\"2997886\"\n",
    "               },\n",
    "               \"district_id\":{\n",
    "                  \"N\":\"565\"\n",
    "               },\n",
    "               \"id\":{\n",
    "                  \"N\":\"118562018\"\n",
    "               },\n",
    "               \"category_group_id\":{\n",
    "                  \"N\":\"1\"\n",
    "               },\n",
    "               \"tag_english\":{\n",
    "                  \"S\":\"Cash-in Request\"\n",
    "               },\n",
    "               \"collected_amount\":{\n",
    "                  \"N\":\"0\"\n",
    "               },\n",
    "               \"warehouse_id\":{\n",
    "                  \"N\":\"1\"\n",
    "               }\n",
    "            },\n",
    "            \"SequenceNumber\":\"571610300000000091106732594\",\n",
    "            \"SizeBytes\":1098,\n",
    "            \"StreamViewType\":\"NEW_AND_OLD_IMAGES\"\n",
    "         },\n",
    "         \"eventSourceARN\":\"arn:aws:dynamodb:us-east-1:876425898567:table/collection_orders/stream/2024-05-29T11:14:01.243\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
