{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77eaa293-3689-4e82-be7c-c0cf32a01b55",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae18e0a-689f-4535-a832-c067a20a8a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install gspread\n",
    "!pip install oauth2client\n",
    "!pip install slackclient\n",
    "!pip install -U snowflake-connector-python\n",
    "!pip install -U snowflake-snowpark-python\n",
    "!pip install --upgrade psycopg2\n",
    "!pip install -U sqlalchemy\n",
    "!pip install df2gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7404cab-22a8-4dc2-9126-69db3760fcf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session \n",
    "import os\n",
    "import boto3\n",
    "import base64\n",
    "import json\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "import time\n",
    "import zipfile\n",
    "import io\n",
    "import sqlalchemy\n",
    "from pathlib import Path\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import sys\n",
    "import requests\n",
    "from botocore.exceptions import ClientError\n",
    "import importlib\n",
    "from io import StringIO\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import re\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7dc945-dac2-4e2d-8157-d36c157c60a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15f8e3b6-c75a-4a00-9b0f-0a5c678f7763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def imports():\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "        \n",
    "def initialize_env():\n",
    "    snowflake_sg_secret = json.loads(get_secret(\"Snowflake-sagemaker\"))\n",
    "    dwh_writer_secret = json.loads(get_secret(\"prod/db/datawarehouse/sagemaker\"))\n",
    "    metabase_secret = json.loads(get_secret(\"prod/metabase/maxab_config\"))\n",
    "\n",
    "    os.environ[\"SNOWFLAKE_USERNAME\"] = snowflake_sg_secret[\"username\"]\n",
    "    os.environ[\"SNOWFLAKE_PASSWORD\"] = snowflake_sg_secret[\"password\"]\n",
    "    os.environ[\"SNOWFLAKE_ACCOUNT\"] = snowflake_sg_secret[\"account\"]\n",
    "    os.environ[\"SNOWFLAKE_DATABASE\"] = snowflake_sg_secret[\"morocco_database\"]\n",
    "\n",
    "    os.environ[\"DWH_WRITER_HOST_NEW\"] = dwh_writer_secret[\"host\"]\n",
    "    os.environ[\"DWH_WRITER_NAME_NEW\"] = dwh_writer_secret[\"dbname\"]\n",
    "    os.environ[\"DWH_WRITER_USER_NAME_NEW\"] = dwh_writer_secret[\"username\"]\n",
    "    os.environ[\"DWH_WRITER_PASSWORD_NEW\"] = dwh_writer_secret[\"password\"]\n",
    "    \n",
    "    os.environ[\"AFRICA_METABASE_USERNAME\"] = metabase_secret[\"metabase_user\"]\n",
    "    os.environ[\"AFRICA_METABASE_PASSWORD\"] = metabase_secret[\"metabase_password\"]\n",
    "    os.environ[\"AFRICA_METABASE_URL\"] = metabase_secret[\"metabase_morocco_site\"]\n",
    "\n",
    "    json_path_sheets = str(Path.home()) + \"/service_account_key_sheets.json\"\n",
    "    sheets_key = get_secret(\"prod/maxab-sheets\")\n",
    "    f = open(json_path_sheets, \"w\")\n",
    "    f.write(sheets_key)\n",
    "    f.close()\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"] = json_path_sheets\n",
    "    \n",
    "\n",
    "def get_from_gsheet(workbook, sheet):\n",
    "    scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "    initialize_env()\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"], scope)\n",
    "    client = gspread.authorize(creds)\n",
    "    try:\n",
    "        wks = client.open(workbook).worksheet(sheet)\n",
    "        sheet = pd.DataFrame(wks.get_all_records())\n",
    "    except:\n",
    "        print(sheet,'failed to fetch data')\n",
    "    \n",
    "    return sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efc9d60-7860-4f92-8932-8a8b3fad27ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import oauth2client\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from pprint import pprint\n",
    "from df2gspread import df2gspread as d2g\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "import importlib\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import datetime\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "initialize_env()\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "# define the scope\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "# add credentials to the account\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"], scope)\n",
    "# authorize the clientsheet\n",
    "client = gspread.authorize(creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5ae5b5-a69d-4de6-bbd3-cc2169d53209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from io import StringIO, BytesIO\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "def ret_metabase(base_url, username, password, card_id):\n",
    "    card_id = str(card_id)\n",
    "\n",
    "    initialize_env()\n",
    "\n",
    "    base_url = base_url + 'api'\n",
    "    base_headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    try:\n",
    "        s_response = requests.post(\n",
    "            base_url + '/session',\n",
    "            data=json.dumps({\n",
    "                'username': username,\n",
    "                'password': password\n",
    "            }),\n",
    "            headers=base_headers)\n",
    "\n",
    "        s_response.raise_for_status()\n",
    "\n",
    "        session_token = s_response.json()['id']\n",
    "        base_headers['X-Metabase-Session'] = session_token\n",
    "\n",
    "        p_response = requests.post(\n",
    "            base_url + '/card/' + card_id + '/query/xlsx',\n",
    "            headers=base_headers\n",
    "        )\n",
    "        p_response.raise_for_status()\n",
    "\n",
    "        my_dict = p_response.content\n",
    "        xlsx_data = BytesIO(my_dict)\n",
    "        df = pd.read_excel(xlsx_data, engine='openpyxl')\n",
    "        df.columns = df.columns.str.lower()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "#run query save on metabse with ID, \n",
    "#for example here query 1606 is save in my personal collection and I can run it like line below\n",
    "# ret_metabase( os.environ[\"AFRICA_METABASE_URL\"],os.environ[\"AFRICA_METABASE_USERNAME\"],os.environ[\"AFRICA_METABASE_PASSWORD\"],9707)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b08599-6115-4765-905c-c3906dd16e05",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc3acf91-9283-40c5-b154-e01e3b2476f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## assigning data in any project\n",
    "def assign_data(df, list):\n",
    "\n",
    "    actual_length = len(df) % len(list)\n",
    "    rows_needed = len(list) - actual_length\n",
    "    columns_needed = len(df.axes[1])\n",
    "    print(rows_needed)\n",
    "    print(columns_needed)\n",
    "    df = df.sample(frac=1)\n",
    "    empty_df = pd.DataFrame(index=np.arange(rows_needed), columns=np.arange(columns_needed))\n",
    "    assgn = pd.concat([df, empty_df])\n",
    "    assgn = assgn.dropna(axis=1, how='all')\n",
    "    mplr = len(assgn) / len(list) \n",
    "    assgn = assgn.assign(agent_assigned=[val for val in list for _ in range(int(mplr))])\n",
    "    assgn = assgn.dropna()\n",
    "    # print(assgn)\n",
    "    if assgn.shape[1] != 1:\n",
    "\n",
    "            assgn[\"retailer_id\"] = assgn[\"retailer_id\"].fillna('').astype(str).str.replace(\".0\",\"\",regex=False)\n",
    "            assgn[\"mobile\"] = assgn[\"mobile\"].fillna('').astype(str).str.replace(\".0\",\"\",regex=False)\n",
    "            # df = assgn.groupby('agent_assigned').head(assigns)\n",
    "            return assgn\n",
    "    else:\n",
    "            assgn.drop(['agent_assigned'], axis=1)\n",
    "            assgn = assgn.iloc[0:0]\n",
    "            assgn = assgn.assign(index=\"\", retailer_id = \"\",name = \"\", mobile=\"\",sales_order_id=\"\",created_at=\"\",updated_at=\"\",total_order_price=\"\",agent_assigned=\"\")\n",
    "            assgn = assgn[[\"index\",\"retailer_id\",\"name\",\"mobile\",\"sales_order_id\",\"created_at\",\"updated_at\",\"total_order_price\",\"agent_assigned\"]]\n",
    "            # df = assgn.groupby('agent_assigned').head(assigns)\n",
    "            return assgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24dfb9ad-9a0a-46b6-97cc-0913fca6b203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday\n",
      "0    agent_name agent_id start_time end_time          days_off\n",
      "0   Fatima Gasi      109          8       18  Satruday, Sunday\n",
      "1  Doha Rajraji      108          8       18  Saturday, Sunday\n",
      "9\n",
      "0    agent_name agent_id start_time end_time          days_off  \\\n",
      "0   Fatima Gasi      109          8       18  Satruday, Sunday   \n",
      "1  Doha Rajraji      108          8       18  Saturday, Sunday   \n",
      "\n",
      "0  assignment_start_time  assignment_end_time     agents_days_off assign_data  \n",
      "0                      8                   18  [Satruday, Sunday]         yes  \n",
      "1                      8                   18  [Saturday, Sunday]         yes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "initialize_env()\n",
    "\n",
    "# Time zone for Morocco\n",
    "morocco_tz = pytz.timezone('Africa/Casablanca')\n",
    "\n",
    "# Get current time in Moroccan time zone\n",
    "now = datetime.now(morocco_tz)\n",
    "current_time = now.time()\n",
    "current_day = now.strftime('%A')\n",
    "print(current_day)\n",
    "hour = int(str(now.time())[0:2])\n",
    "# print(now)\n",
    "# print(current_day)\n",
    "# print(hour)\n",
    "\n",
    "#Agents sheet\n",
    "scope = [\n",
    "    \"https://spreadsheets.google.com/feeds\",\n",
    "    'https://www.googleapis.com/auth/spreadsheets',\n",
    "    \"https://www.googleapis.com/auth/drive.file\",\n",
    "    \"https://www.googleapis.com/auth/drive\"\n",
    "]\n",
    "\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"], scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "sheet = client.open('[HOURLY] Fintech Runsheet')\n",
    "agents_sheet_instance = sheet.worksheet('agents_sheet')\n",
    "agents_df = pd.DataFrame(agents_sheet_instance.get())\n",
    "agents_df.columns = agents_df.iloc[0]\n",
    "agents_df = agents_df[1:]\n",
    "agents_df.reset_index(drop=True, inplace=True)\n",
    "print(agents_df)\n",
    "# agents_df\n",
    "print(hour)\n",
    "#Agents Assignment \n",
    "agents_df_copy = agents_df.copy()\n",
    "agents_df_copy['assignment_start_time'] = agents_df['start_time'].astype(int)\n",
    "agents_df_copy['assignment_end_time'] = agents_df['end_time'].astype(int)\n",
    "agents_df_copy['agents_days_off'] = agents_df['days_off'].str.split(', ')\n",
    "\n",
    "agents_df_copy['assign_data'] =  np.where((hour >= agents_df_copy['assignment_start_time'] )\n",
    "                                &\n",
    "                                (hour <= agents_df_copy['assignment_end_time'])\n",
    "                                & \n",
    "                                (str(current_day) not in str(agents_df_copy['agents_days_off']) )\n",
    "                                , 'yes','no' )\n",
    "\n",
    "# agents_df_copy['assign_data'] =  np.where(agents_df['agent_id']==108\n",
    "#                                 , 'yes','no' )\n",
    "\n",
    "print(agents_df_copy)\n",
    "available_agents = agents_df_copy.loc[agents_df_copy['assign_data'] =='yes']\n",
    "available_agents_list = available_agents['agent_id'].values.tolist()\n",
    "number_of_available_agents = len(available_agents_list)\n",
    "# print(number_of_available_agents)\n",
    "\n",
    "\n",
    "if number_of_available_agents != 0:\n",
    "    \n",
    "    #en route query \n",
    "    # df_1 = ret_metabase( os.environ[\"AFRICA_METABASE_URL\"],os.environ[\"AFRICA_METABASE_USERNAME\"],os.environ[\"AFRICA_METABASE_PASSWORD\"],10000)\n",
    "    \n",
    "    #created and delivery tomorrow query \n",
    "    df_1 = ret_metabase( os.environ[\"AFRICA_METABASE_URL\"],os.environ[\"AFRICA_METABASE_USERNAME\"],os.environ[\"AFRICA_METABASE_PASSWORD\"],10085)\n",
    "    \n",
    "    #data cleaning \n",
    "    df_1.columns = map(str.lower, df_1.columns)\n",
    "    df_1 = df_1.drop_duplicates(subset=['retailer_id'], keep=\"first\")\n",
    "    df_1 = df_1.reset_index(drop=True)\n",
    "    # print(df_1)\n",
    "    \n",
    "    #Remove the data that already exists if found \n",
    "    sheet = client.open('[HOURLY] Fintech Runsheet')\n",
    "    data_instance = sheet.worksheet('Data')\n",
    "    data_instance_df= pd.DataFrame(data_instance.get('E5:E'))\n",
    "    # print(data_instance_df)\n",
    "\n",
    "    if(data_instance_df.empty==False):\n",
    "        data_instance_df.columns = ['sales_order_id']\n",
    "        main_data_to_assign = pd.DataFrame(df_1.loc[~df_1['sales_order_id'].isin(data_instance_df['sales_order_id'].astype(int).values)])\n",
    "        main_data_assigned = assign_data(main_data_to_assign,available_agents_list)\n",
    "        # print(main_data_assigned)\n",
    "    else:\n",
    "        main_data_to_assign = df_1.copy()\n",
    "        main_data_assigned = assign_data(main_data_to_assign,available_agents_list)\n",
    "        # print(main_data_assigned)\n",
    "        \n",
    "    # agents_df.columns = agents_df.iloc[0]\n",
    "    # agents_df = agents_df[1:]\n",
    "    # agents_df.reset_index(drop=True, inplace=True)\n",
    "    # agents_df\n",
    "#     grouped_counts = main_data_assigned.groupby('agent_assigned').size().reset_index(name='count')\n",
    "#     print(grouped_counts)\n",
    "\n",
    "    #importing data in agents' sheet\n",
    "    final_data_to_assign = main_data_assigned.copy()\n",
    "    # final_data_to_assign = final_data_to_assign\n",
    "    # final_data_to_assign = final_data_to_assign.drop_duplicates(subset='retailer_id', keep=\"first\")\n",
    "    final_data_to_assign['added_at'] = now.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    if final_data_to_assign.columns[0] == 'index':\n",
    "        final_data_to_assign = final_data_to_assign.drop(labels='index', axis=1)\n",
    "    pass\n",
    "\n",
    "    final_data_to_assign = final_data_to_assign.astype(str)\n",
    "    google_sh = client.open('[HOURLY] Fintech Runsheet')\n",
    "    sheet = google_sh.worksheet('raw_data')\n",
    "    # sheet.clear()\n",
    "    sheet.append_rows([final_data_to_assign.columns.values.tolist()] + final_data_to_assign.values.tolist(), value_input_option=\"USER_ENTERED\")\n",
    "else:\n",
    "    print(\"no agents available\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
