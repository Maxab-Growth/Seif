{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e5a364-d408-4a25-a886-e5d40af86ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gspread in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (6.2.1)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gspread) (2.40.1)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gspread) (1.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.1.31)\n",
      "Requirement already satisfied: oauth2client in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.1.3)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from oauth2client) (0.22.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from oauth2client) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from oauth2client) (0.4.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from oauth2client) (4.7.2)\n",
      "Requirement already satisfied: six>=1.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from oauth2client) (1.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httplib2>=0.9.1->oauth2client) (3.2.3)\n",
      "Requirement already satisfied: slackclient in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.9.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>3.5.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from slackclient) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>3.5.2->slackclient) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>3.5.2->slackclient) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>3.5.2->slackclient) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>3.5.2->slackclient) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>3.5.2->slackclient) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>3.5.2->slackclient) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>3.5.2->slackclient) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>3.5.2->slackclient) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp<4.0.0,>3.5.2->slackclient) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>3.5.2->slackclient) (3.10)\n",
      "Requirement already satisfied: snowflake-connector-python in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.15.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: boto3>=1.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (1.38.0)\n",
      "Requirement already satisfied: botocore>=1.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (1.38.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (44.0.2)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (25.0.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (2025.2)\n",
      "Requirement already satisfied: requests<3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (2.32.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (24.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (4.13.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (3.16.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (4.3.7)\n",
      "Requirement already satisfied: tomlkit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python) (0.13.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3>=1.24->snowflake-connector-python) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3>=1.24->snowflake-connector-python) (0.12.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.24->snowflake-connector-python) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.24->snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.17.0)\n",
      "Requirement already satisfied: snowflake-snowpark-python in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.32.0)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (79.0.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (0.45.1)\n",
      "Requirement already satisfied: snowflake-connector-python<4.0.0,>=3.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (4.13.2)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (6.0.2)\n",
      "Requirement already satisfied: cloudpickle!=2.1.0,!=2.2.0,<=3.0.0,>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (3.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (5.29.4)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (2.9.0.post0)\n",
      "Requirement already satisfied: tzlocal in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-snowpark-python) (5.3.1)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (1.5.1)\n",
      "Requirement already satisfied: boto3>=1.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (1.38.0)\n",
      "Requirement already satisfied: botocore>=1.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (1.38.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (44.0.2)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (25.0.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (2025.2)\n",
      "Requirement already satisfied: requests<3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (2.32.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (24.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (2025.1.31)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (3.16.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (4.3.7)\n",
      "Requirement already satisfied: tomlkit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (0.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil->snowflake-snowpark-python) (1.17.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3>=1.24->snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3>=1.24->snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (0.12.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.24->snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (2.4.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<4.0.0,>=3.14.0->snowflake-snowpark-python) (2.22)\n",
      "Requirement already satisfied: psycopg2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.9.10)\n",
      "Requirement already satisfied: sqlalchemy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.0.41)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy) (4.13.2)\n",
      "Requirement already satisfied: df2gspread in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.0.4)\n",
      "Collecting argparse>=1.3.0 (from df2gspread)\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: google-api-python-client==1.6.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from df2gspread) (1.6.7)\n",
      "Requirement already satisfied: gspread>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from df2gspread) (6.2.1)\n",
      "Requirement already satisfied: oauth2client<5.0.0dev,>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from df2gspread) (4.1.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from df2gspread) (1.5.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-python-client==1.6.7->df2gspread) (0.22.0)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-python-client==1.6.7->df2gspread) (1.17.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-python-client==1.6.7->df2gspread) (3.0.1)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gspread>=2.1.1->df2gspread) (2.40.1)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gspread>=2.1.1->df2gspread) (1.2.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from oauth2client<5.0.0dev,>=1.5.0->df2gspread) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from oauth2client<5.0.0dev,>=1.5.0->df2gspread) (0.4.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from oauth2client<5.0.0dev,>=1.5.0->df2gspread) (4.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->df2gspread) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->df2gspread) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->df2gspread) (1.26.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread>=2.1.1->df2gspread) (5.5.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth-oauthlib>=0.4.1->gspread>=2.1.1->df2gspread) (2.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.6.7->df2gspread) (3.2.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=2.1.1->df2gspread) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=2.1.1->df2gspread) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=2.1.1->df2gspread) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=2.1.1->df2gspread) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=2.1.1->df2gspread) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=2.1.1->df2gspread) (2025.1.31)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install gspread\n",
    "!pip install oauth2client\n",
    "!pip install slackclient\n",
    "!pip install -U snowflake-connector-python\n",
    "!pip install -U snowflake-snowpark-python\n",
    "!pip install --upgrade psycopg2\n",
    "!pip install -U sqlalchemy\n",
    "!pip install df2gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e7cf80-ac47-4c1e-b4c5-84fa231f193a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from snowflake.snowpark import Session \n",
    "import os\n",
    "import boto3\n",
    "import base64\n",
    "import json\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "import time\n",
    "import zipfile\n",
    "import io\n",
    "import sqlalchemy\n",
    "from pathlib import Path\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import sys\n",
    "import requests\n",
    "from botocore.exceptions import ClientError\n",
    "import importlib\n",
    "from io import StringIO\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import re\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d2c17f-d181-41f1-863b-61c4bfa9df56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def imports():\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "        \n",
    "def initialize_env():\n",
    "    snowflake_sg_secret = json.loads(get_secret(\"Snowflake-sagemaker\"))\n",
    "    slack_secret = json.loads(get_secret(\"prod/slack/reports\"))\n",
    "    rowaa_metabase_access = json.loads(get_secret(\"prod/metabase/rowaa/user\"))\n",
    "    dwh_writer_secret = json.loads(get_secret(\"prod/db/datawarehouse/sagemaker\"))\n",
    "\n",
    "    os.environ[\"SNOWFLAKE_USERNAME\"] = snowflake_sg_secret[\"username\"]\n",
    "    os.environ[\"SNOWFLAKE_PASSWORD\"] = snowflake_sg_secret[\"password\"]\n",
    "    os.environ[\"SNOWFLAKE_ACCOUNT\"] = snowflake_sg_secret[\"account\"]\n",
    "    os.environ[\"SNOWFLAKE_DATABASE\"] = snowflake_sg_secret[\"database\"]\n",
    "\n",
    "    os.environ[\"SLACK_TOKEN\"] = slack_secret[\"token\"]\n",
    "\n",
    "    os.environ[\"METABASE_USERNAME_ROWAA\"] = rowaa_metabase_access[\"username\"]\n",
    "    os.environ[\"METABASE_PASSWORD_ROWAA\"] = rowaa_metabase_access[\"password\"]\n",
    "\n",
    "    os.environ[\"DWH_WRITER_HOST_NEW\"] = dwh_writer_secret[\"host\"]\n",
    "    os.environ[\"DWH_WRITER_NAME_NEW\"] = dwh_writer_secret[\"dbname\"]\n",
    "    os.environ[\"DWH_WRITER_USER_NAME_NEW\"] = dwh_writer_secret[\"username\"]\n",
    "    os.environ[\"DWH_WRITER_PASSWORD_NEW\"] = dwh_writer_secret[\"password\"] \n",
    "\n",
    "    json_path_sheets = str(Path.home()) + \"/service_account_key_sheets.json\"\n",
    "    sheets_key = get_secret(\"prod/maxab-sheets\")\n",
    "    f = open(json_path_sheets, \"w\")\n",
    "    f.write(sheets_key)\n",
    "    f.close()\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"] = json_path_sheets\n",
    "    \n",
    "\n",
    "def get_from_gsheet(workbook, sheet):\n",
    "    scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "    initialize_env()\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"], scope)\n",
    "    client = gspread.authorize(creds)\n",
    "    try:\n",
    "        wks = client.open(workbook).worksheet(sheet)\n",
    "        sheet = pd.DataFrame(wks.get_all_records())\n",
    "    except:\n",
    "        print(sheet,'failed to fetch data')\n",
    "    \n",
    "    return sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdde1c8-3228-445e-a845-4342aba93cd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19a379a-8074-449c-acfc-25038495e129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "def ret_metabase(username, password, question):\n",
    "    base_url = 'https://bi.maxab.info/api'\n",
    "    base_headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    try:\n",
    "        s_response = requests.post(\n",
    "            base_url + '/session',\n",
    "            data=json.dumps({\n",
    "                'username': username,\n",
    "                'password': password\n",
    "            }),\n",
    "            headers=base_headers)\n",
    "        s_response.raise_for_status()\n",
    "\n",
    "        session_token = s_response.json()['id']\n",
    "        base_headers['X-Metabase-Session'] = session_token\n",
    "\n",
    "        p_response = requests.post(base_url + '/card/' + str(question) + '/query/csv', headers=base_headers)\n",
    "        p_response.raise_for_status()\n",
    "\n",
    "        my_dict = p_response.content\n",
    "        s = str(my_dict, 'utf-8')\n",
    "        my_dict = StringIO(s)\n",
    "        df = pd.read_csv(my_dict)\n",
    "        return(df)\n",
    "\n",
    "    except Exception as e:\n",
    "         print(e)\n",
    "\n",
    "    \n",
    "#run query save on metabse with ID, \n",
    "#for example here query 1606 is save in my personal collection and I can run it like line below\n",
    "# ret_metabase(1606)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de4cc31-c812-440f-8527-5fdaa04fd61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_data_equal_projects(df, list, assigns):\n",
    "    df = df.sample(frac=1)  # Shuffle the data\n",
    "    project_types = df['project_name'].unique()\n",
    "    \n",
    "    assigned_data = pd.DataFrame()\n",
    "    \n",
    "    for project in project_types:\n",
    "        project_df = df[df['project_name'] == project]\n",
    "        project_df = project_df.reset_index(drop=True)\n",
    "        rows_per_agent = len(project_df) // len(list)\n",
    "        remainder = len(project_df) % len(list)\n",
    "        \n",
    "        # Distribute rows equally\n",
    "        for i, agent in enumerate(list):\n",
    "            start_idx = i * rows_per_agent\n",
    "            end_idx = start_idx + rows_per_agent\n",
    "            agent_data = project_df.iloc[start_idx:end_idx].copy()\n",
    "            agent_data['agent_assigned'] = agent\n",
    "            \n",
    "            # Handle remainder\n",
    "            if i < remainder:\n",
    "                extra_row = project_df.iloc[end_idx:end_idx+1].copy()\n",
    "                extra_row['agent_assigned'] = agent\n",
    "                agent_data = pd.concat([agent_data, extra_row])\n",
    "            \n",
    "            assigned_data = pd.concat([assigned_data, agent_data])\n",
    "    \n",
    "    assigned_data = assigned_data.reset_index(drop=True)\n",
    "    \n",
    "    return assigned_data\n",
    "\n",
    "\n",
    "def clean_column_id(df, column_name):\n",
    "    # Ensure the column is treated as a string\n",
    "    df[column_name] = df[column_name].astype(str)\n",
    "    \n",
    "    # Replace commas in the string\n",
    "    df[column_name] = df[column_name].str.replace(',', '')\n",
    "    \n",
    "    # Convert back to an integer, if appropriate\n",
    "    df[column_name] = df[column_name].astype('Int64', errors='ignore')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d6a966-f8e0-49cb-9324-31a467356834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assign tasks by mapping \n",
    "def assign_data_by_mapping(df, mapping_df):\n",
    "    # store retail-agent mapping in a dictionary \n",
    "    mapping_dict = dict(zip(mapping_df['main_system_id'], mapping_df['agent_assigned']))\n",
    "    \n",
    "    \n",
    "    assigned_agents = []\n",
    "    # missing_retailers = [] could use it later for viewing errors\n",
    "\n",
    "    for retailer_id in df['main_system_id']:\n",
    "        if retailer_id in mapping_dict:\n",
    "            assigned_agents.append(mapping_dict[retailer_id])\n",
    "        else:\n",
    "            assigned_agents.append(None)\n",
    "            \n",
    "\n",
    "    \n",
    "    df['agent_assigned'] = assigned_agents\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20837716-4453-4b08-8791-e0b7a2b31c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_env():\n",
    "    snowflake_sg_secret = json.loads(get_secret(\"Snowflake-sagemaker\"))\n",
    "    slack_secret = json.loads(get_secret(\"prod/slack/reports\"))\n",
    "    fintech_service_account = json.loads(get_secret(\"prod/fintechServiceEmail/credentials\"))\n",
    "    dwh_writer_secret = json.loads(get_secret(\"prod/db/datawarehouse/sagemaker\"))\n",
    "\n",
    "    os.environ[\"SNOWFLAKE_USERNAME\"] = snowflake_sg_secret[\"username\"]\n",
    "    os.environ[\"SNOWFLAKE_PASSWORD\"] = snowflake_sg_secret[\"password\"]\n",
    "    os.environ[\"SNOWFLAKE_ACCOUNT\"] = snowflake_sg_secret[\"account\"]\n",
    "    os.environ[\"SNOWFLAKE_DATABASE\"] = snowflake_sg_secret[\"database\"]\n",
    "\n",
    "    os.environ[\"SLACK_TOKEN\"] = slack_secret[\"token\"]\n",
    "\n",
    "    os.environ[\"FINTECH_EMONEY_EMAIL\"] = fintech_service_account[\"email_name\"]\n",
    "    os.environ[\"FINTECH_EMONEY_PASSWORD\"] = fintech_service_account[\"email_password\"]\n",
    "\n",
    "    metabase_secret = json.loads(get_secret(\"prod/metabase/maxab_config\"))\n",
    "    os.environ[\"EGYPT_METABASE_USERNAME\"] = metabase_secret[\"metabase_user\"]\n",
    "    os.environ[\"EGYPT_METABASE_PASSWORD\"] = metabase_secret[\"metabase_password\"]\n",
    "\n",
    "    os.environ[\"DWH_WRITER_HOST_NEW\"] = dwh_writer_secret[\"host\"]\n",
    "    os.environ[\"DWH_WRITER_NAME_NEW\"] = dwh_writer_secret[\"dbname\"]\n",
    "    os.environ[\"DWH_WRITER_USER_NAME_NEW\"] = dwh_writer_secret[\"username\"]\n",
    "    os.environ[\"DWH_WRITER_PASSWORD_NEW\"] = dwh_writer_secret[\"password\"] \n",
    "\n",
    "    json_path_sheets = str(Path.home()) + \"/service_account_key_sheets.json\"\n",
    "    sheets_key = get_secret(\"prod/maxab-sheets\")\n",
    "    f = open(json_path_sheets, \"w\")\n",
    "    f.write(sheets_key)\n",
    "    f.close()\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"] = json_path_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e8934e5-d82b-4be4-9664-5a15be05c3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_assign(previously_assigned, df, assigns):\n",
    "    if  previously_assigned.shape[0] != 1:\n",
    "        previously_assigned[0] = previously_assigned[0].fillna('').astype(str).str.replace(\" \",\"\",regex=False)\n",
    "        previously_assigned = previously_assigned.dropna()\n",
    "        previously_assigned[0] = previously_assigned[0].astype('float')\n",
    "        previously_assigned[0] = previously_assigned[0].astype('int')\n",
    "        df['main_system_id'] = df['main_system_id'].astype('int')\n",
    "\n",
    "        # Filter out previously assigned IDs but keep main_system_id == 1\n",
    "        main_data_to_assign = pd.DataFrame(\n",
    "            df.loc[~df['main_system_id'].isin(previously_assigned[0].astype(int).values) | (df['main_system_id'] == 1)]\n",
    "        )    \n",
    "\n",
    "        main_data_to_assign['main_system_id'] = main_data_to_assign['main_system_id'].astype('int')\n",
    "        main_data_to_assign = main_data_to_assign.groupby('agent_assigned').head(assigns)\n",
    "        return main_data_to_assign\n",
    "    else:\n",
    "        df['main_system_id'] = df['main_system_id'].astype('int')\n",
    "        main_data_to_assign = df.groupby('agent_assigned').head(assigns)\n",
    "        return main_data_to_assign\n",
    "\n",
    "def assign_data_equal_projects(df, list, assigns):\n",
    "    df = df.sample(frac=1)  # Shuffle the data\n",
    "    project_types = df['project_name'].unique()\n",
    "    \n",
    "    assigned_data = pd.DataFrame()\n",
    "    \n",
    "    for project in project_types:\n",
    "        project_df = df[df['project_name'] == project]\n",
    "        project_df = project_df.reset_index(drop=True)\n",
    "        rows_per_agent = len(project_df) // len(list)\n",
    "        remainder = len(project_df) % len(list)\n",
    "        \n",
    "        # Distribute rows equally\n",
    "        for i, agent in enumerate(list):\n",
    "            start_idx = i * rows_per_agent\n",
    "            end_idx = start_idx + rows_per_agent\n",
    "            agent_data = project_df.iloc[start_idx:end_idx].copy()\n",
    "            agent_data['agent_assigned'] = agent\n",
    "            \n",
    "            # Handle remainder\n",
    "            if i < remainder:\n",
    "                extra_row = project_df.iloc[end_idx:end_idx+1].copy()\n",
    "                extra_row['agent_assigned'] = agent\n",
    "                agent_data = pd.concat([agent_data, extra_row])\n",
    "            \n",
    "            assigned_data = pd.concat([assigned_data, agent_data])\n",
    "    \n",
    "    assigned_data = assigned_data.reset_index(drop=True)\n",
    "    \n",
    "    return assigned_data\n",
    "\n",
    "def check_distribution(df, agent_list):\n",
    "    \"\"\"\n",
    "    Checks if the distribution of project types across agents is even.\n",
    "    Returns a dictionary with the count of rows per agent for each project type.\n",
    "    \"\"\"\n",
    "    distribution = {}\n",
    "    project_types = df['project_name'].unique()\n",
    "    \n",
    "    for project in project_types:\n",
    "        project_df = df[df['project_name'] == project]\n",
    "        distribution[project] = project_df['agent_assigned'].value_counts().reindex(agent_list, fill_value=0)\n",
    "    \n",
    "    return distribution\n",
    "\n",
    "def redistribute_rows(df, agent_list):\n",
    "    \"\"\"\n",
    "    Redistributes rows among agents if the distribution is uneven.\n",
    "    \"\"\"\n",
    "    project_types = df['project_name'].unique()\n",
    "    redistributed_data = pd.DataFrame()\n",
    "    \n",
    "    for project in project_types:\n",
    "        project_df = df[df['project_name'] == project]\n",
    "        project_df = project_df.sample(frac=1).reset_index(drop=True)  # Shuffle data\n",
    "        rows_per_agent = len(project_df) // len(agent_list)\n",
    "        remainder = len(project_df) % len(agent_list)\n",
    "        \n",
    "        start_idx = 0\n",
    "        \n",
    "        for i, agent in enumerate(agent_list):\n",
    "            end_idx = start_idx + rows_per_agent + (1 if i < remainder else 0)\n",
    "            agent_data = project_df.iloc[start_idx:end_idx].copy()\n",
    "            agent_data['agent_assigned'] = agent\n",
    "            \n",
    "            redistributed_data = pd.concat([redistributed_data, agent_data])\n",
    "            \n",
    "            start_idx = end_idx\n",
    "    \n",
    "    redistributed_data = redistributed_data.reset_index(drop=True)\n",
    "    \n",
    "    return redistributed_data\n",
    "\n",
    "def ensure_correct_dispatching(df, agent_list, final_old_assign):\n",
    "    \"\"\"\n",
    "    Ensures the dispatching is done correctly by checking and redistributing rows if necessary.\n",
    "    `final_old_assign` rows are excluded from redistribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Exclude final_old_assign from the distribution check, but keep rows with main_system_id == 1\n",
    "    new_assignments = df[~df['main_system_id'].isin(final_old_assign['main_system_id']) | (df['main_system_id'] == 1)]\n",
    "    \n",
    "    distribution = check_distribution(new_assignments, agent_list)\n",
    "    \n",
    "    # Check if any project has an uneven distribution across agents\n",
    "    uneven_distribution = any(distribution[project].nunique() > 1 for project in distribution)\n",
    "    \n",
    "    if uneven_distribution:\n",
    "        print(\"Uneven distribution detected. Redistributing rows...\")\n",
    "        new_assignments = redistribute_rows(new_assignments, agent_list)\n",
    "    else:\n",
    "        print(\"Distribution is even. No redistribution needed.\")\n",
    "    \n",
    "    # Combine the redistributed new assignments with the final_old_assign\n",
    "    final_data = pd.concat([final_old_assign, new_assignments], ignore_index=True)\n",
    "    \n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f59641f-771a-489e-ae65-7d7e834b62df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   main_system_id                             retailer_mobile_number  \\\n",
      "2            2311  B40B35373E4BB016E00ED3-9FF662DFF654B5AF0496666...   \n",
      "\n",
      "  retailer_name                                        description reward  \\\n",
      "2      الطاحونة   Project : segment based project, لو اشتغلت مع...      5   \n",
      "\n",
      "  balance offer  agent_assigned           project_name  \n",
      "2       0  1000          4078.0  segment based project  \n",
      "Uneven distribution detected. Redistributing rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11372/121347767.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['main_system_id'] = df['main_system_id'].astype('int')\n"
     ]
    }
   ],
   "source": [
    "initialize_env()\n",
    "# get todays date\n",
    "now = datetime.now() + timedelta(hours=3)\n",
    "# get todays hour\n",
    "hour = int(str(now.time())[0:2])\n",
    "# detrmine agent availabilty\n",
    "#access agent dataset\n",
    "attendance = ret_metabase(os.environ[\"EGYPT_METABASE_USERNAME\"], os.environ[\"EGYPT_METABASE_PASSWORD\"], 13502)\n",
    "attendance_copy = attendance.copy()\n",
    "# copy date from agent dataset as integers\n",
    "attendance_copy['start_time'] = attendance_copy['start_time'].astype(int)\n",
    "attendance_copy['end_time'] = attendance_copy['end_time'].astype(int)\n",
    "# Assignment times are offset by -1 to begin earlier\n",
    "attendance_copy['assignment_start_time'] = attendance_copy['start_time'] - 1\n",
    "attendance_copy['assignment_end_time'] = attendance_copy['end_time'] - 1\n",
    "\n",
    "# Assigns \"yes\" if the current hour is within the active assignment time for an agent\n",
    "attendance_copy['assign_data'] = np.where(\n",
    "(hour >= attendance_copy['assignment_start_time']) & (hour <= attendance_copy['assignment_end_time']),\n",
    "'yes',\n",
    "'no')\n",
    "\n",
    "# filter agents working on \"task_based\" in agent data base under \"project\" & available now\n",
    "task_based_agents = attendance_copy.loc[\n",
    "(attendance_copy['project'] == 'task_based') & (attendance_copy['assign_data'] == 'yes')\n",
    "]\n",
    "# create a list of this agents with just their agent id\n",
    "task_based_list = task_based_agents['agent_id'].values.tolist()\n",
    "# count the number of \"task_based\" agents\n",
    "number_of_task_based_agents = len(task_based_list)\n",
    "# wait 15 sec to allow sync \n",
    "time.sleep(15)\n",
    "# if agents are available ->\n",
    "if number_of_task_based_agents != 0:\n",
    "# setup the environment:\n",
    "        initialize_env()\n",
    "\n",
    "        scope = [\n",
    "            \"https://spreadsheets.google.com/feeds\",\n",
    "            'https://www.googleapis.com/auth/spreadsheets',\n",
    "            \"https://www.googleapis.com/auth/drive.file\",\n",
    "            \"https://www.googleapis.com/auth/drive\"\n",
    "        ]\n",
    "\n",
    "        creds = ServiceAccountCredentials.from_json_keyfile_name(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"], scope)\n",
    "        client = gspread.authorize(creds)\n",
    "\n",
    "        # queris to use to assign tasks to agents\n",
    "        query_ids = [18915, 36299, 35981, 38188, 49566, 56316, 59170, 59188]\n",
    "        # queries to use to assign tasks to agents (no random assigning)(fixed Agent to retailer relationship)\n",
    "        queries_for_mapped = ret_metabase(os.environ[\"EGYPT_METABASE_USERNAME\"], os.environ[\"EGYPT_METABASE_PASSWORD\"], 59585)\n",
    "        \n",
    "        queries_for_mapped.columns = queries_for_mapped.columns.str.lower()\n",
    "\n",
    "\n",
    "        # retrive data from the  queries datasets \n",
    "        dataframes = [ret_metabase(os.environ[\"EGYPT_METABASE_USERNAME\"], os.environ[\"EGYPT_METABASE_PASSWORD\"], qid) for qid in query_ids]\n",
    "        for df in dataframes:\n",
    "            df.columns = map(str.lower, df.columns)\n",
    "\n",
    "        # Concatenate the DataFrames along the rows (union all)\n",
    "        df_unfiltered = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "        # Excluding blacklisted retailers\n",
    "        blacklisted_retailers = [214101,663943,667569,523168,604291,525506,671719,266692,26115,373055]\n",
    "        # ~ store data without main_system_id where blacklisted_retailer ids are in it\n",
    "        df_raw = df_unfiltered[~df_unfiltered['main_system_id'].isin(blacklisted_retailers)]\n",
    "        df_raw = clean_column_id(df_raw, 'main_system_id')\n",
    "        queries_for_mapped = queries_for_mapped[~queries_for_mapped['main_system_id'].isin(blacklisted_retailers)]\n",
    "\n",
    "        # Fetching old assigns data\n",
    "\n",
    "        # Access previsous assigned retailers \n",
    "        previous_calls = ret_metabase(os.environ[\"EGYPT_METABASE_USERNAME\"], os.environ[\"EGYPT_METABASE_PASSWORD\"], 35299)\n",
    "        previous_calls = clean_column_id(previous_calls, 'main_system_id')\n",
    "        # ~ Exclude Previously Assigned Retailers\n",
    "        df = df_raw.merge(previous_calls, on='main_system_id', how='left')\n",
    "        exclude_same_assigns = clean_column_id(previous_calls,'main_system_id')\n",
    "        task_based = pd.DataFrame(df_raw.loc[~df_raw['main_system_id'].isin(exclude_same_assigns['main_system_id'].astype(int).values)])\n",
    "\n",
    "        # store previously assigned retailers that were removed in old_assgns variable #note these arent included anymore in \"task_based\" variable\n",
    "        old_assgns = pd.DataFrame(df_raw.loc[df_raw['main_system_id'].isin(exclude_same_assigns['main_system_id'].astype(int).values)])\n",
    "        old_assgns = clean_column_id(old_assgns, 'main_system_id')\n",
    "        # Keep Old Assignments (if needed)\n",
    "        # Stores info on old assignments for reference or fallback\n",
    "        df_1 = old_assgns.merge(previous_calls, on='main_system_id', how='left')\n",
    "        final_old_assign = df_1[[\"main_system_id\", \"retailer_mobile_number\",\"retailer_name\",\"description\",\"reward\",\"balance\",\"offer\",\"agent_assigned\",\"project_name\"]]\n",
    "\n",
    "        # Define the range of priorities\n",
    "        priority_range = range(1, 16)  # 1 to 15 inclusive\n",
    "\n",
    "        # Initialize a list to store the results\n",
    "        main_data_list = []\n",
    "\n",
    "        # data from EG Telesales Cycle Assignment \n",
    "        mapping_sheet = client.open('EG Telesales Cycle Assignment')\n",
    "        mapping_worksheet = mapping_sheet.worksheet('Sheet1')  \n",
    "        mapping_data = mapping_worksheet.get_all_values()\n",
    "        mapping_df = pd.DataFrame(mapping_data[1:], columns=mapping_data[0])  # Convert to DataFrame first\n",
    "        mapping_df = clean_column_id(mapping_df, 'main_system_id')\n",
    "        mapping_df = clean_column_id(mapping_df, 'agent_assigned')\n",
    "\n",
    "\n",
    "        mapped_data = assign_data_by_mapping(queries_for_mapped, mapping_df) \n",
    "\n",
    "        main_data_list.append(mapped_data)\n",
    "\n",
    "        # Iterate over each priority level\n",
    "        for priority in priority_range:\n",
    "            # Filter the DataFrame for the current priority\n",
    "            # stores only rows where priority matches priority itteration \n",
    "            priority_df = task_based[task_based[\"priority\"] == priority].reset_index(drop=True)\n",
    "\n",
    "            # Assign data to projects\n",
    "            # use assign_data_equal_projects function to distribute tasks equally \n",
    "            main_data = assign_data_equal_projects(priority_df, task_based_list, 2000)\n",
    "\n",
    "            # Append the result to the list\n",
    "            main_data_list.append(main_data)\n",
    "\n",
    "        # Concatenate all the main_data DataFrames into one\n",
    "        main_data_total = pd.concat(main_data_list, ignore_index=True)\n",
    "\n",
    "        # Filter the data to include the required columns\n",
    "        main_data = main_data_total[\n",
    "            [\"main_system_id\", \"retailer_mobile_number\", \"retailer_name\", \"description\", \"reward\", \"balance\", \"offer\", \"agent_assigned\", \"project_name\"] ]\n",
    "\n",
    "        # Separate rows where main_system_id == 1\n",
    "        main_system_id_1 = main_data[main_data['main_system_id'] == 1]\n",
    "\n",
    "        # Remove duplicates for rows where main_system_id is NOT 1\n",
    "        other_main_system_ids = main_data[main_data['main_system_id'] != 1]\n",
    "        other_main_system_ids = other_main_system_ids.drop_duplicates(subset=['main_system_id'])\n",
    "\n",
    "        # Combine both parts back together\n",
    "        # return both datasets again together with all ids equal 1\n",
    "        main_data = pd.concat([main_system_id_1, other_main_system_ids], ignore_index=True)\n",
    "\n",
    "\n",
    "        # removing previously assigned\n",
    "\n",
    "        sheet = client.open('[HOURLY] TASK-BASED Data')\n",
    "        sheet_instance = sheet.worksheet('Data')\n",
    "        assignments = sheet_instance.get('G5:G')\n",
    "        assignments_df = pd.DataFrame.from_dict(assignments)\n",
    "\n",
    "        df = main_data.copy()\n",
    "       \n",
    "\n",
    "        # Remove previous assignments and filter \n",
    "        main_data_to_assign = remove_assign(assignments_df, df, 40)\n",
    "        final_old_assign_new = remove_assign(assignments_df, final_old_assign, 5)\n",
    "\n",
    "        # Filter the dataframes based on 'agent_assigned' being in task_based_list\n",
    "        filtered_df = main_data_to_assign[main_data_to_assign['agent_assigned'].isin(task_based_list)]\n",
    "        filtered_df_old = final_old_assign_new[final_old_assign_new['agent_assigned'].isin(task_based_list)]\n",
    "\n",
    "        # Importing data into agents' sheet\n",
    "        final_data_to_assign = filtered_df.drop_duplicates(subset='main_system_id', keep='first').copy()\n",
    "        final_old_assign_new = filtered_df_old.drop_duplicates(subset='main_system_id', keep='first').copy()\n",
    "\n",
    "        # Add 'added_at' timestamp\n",
    "        final_data_to_assign['added_at'] = now\n",
    "        final_old_assign_new['added_at'] = now\n",
    "\n",
    "        # Remove 'index' column if it exists\n",
    "        final_data_to_assign = final_data_to_assign.drop(columns='index', errors='ignore')\n",
    "\n",
    "        final_data_to_assign = ensure_correct_dispatching(final_data_to_assign, task_based_list, final_old_assign_new)\n",
    "\n",
    "        final_data_to_assign = final_data_to_assign.astype(str)\n",
    "        sheet_df = final_data_to_assign[[\"main_system_id\", \"retailer_mobile_number\",\"retailer_name\",\"description\",\"reward\",\"balance\",\"offer\",\"agent_assigned\",\"added_at\"]]\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
