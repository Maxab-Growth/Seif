{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56001ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import http.client\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "# import snowflake.connector\n",
    "from datetime import datetime\n",
    "\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "dynamodb_table = dynamodb.Table('db_trigger')\n",
    "\n",
    "# sending sms:\n",
    "def send_message(messagesObject, tag=None):\n",
    "    auth = \"App b9c03ee856baa2b7ac96b4b0ecb8aa36-ce2dbf98-1fd2-4fff-9b8b-0d5b8187c834\"\n",
    "    conn = http.client.HTTPSConnection(\"qg3p63.api.infobip.com\")\n",
    "    if tag is None:\n",
    "        payload = json.dumps({\"messages\": messagesObject})\n",
    "    else:\n",
    "        payload = json.dumps({\"bulkId\": tag, \"messages\": messagesObject})\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': \"App b9c03ee856baa2b7ac96b4b0ecb8aa36-ce2dbf98-1fd2-4fff-9b8b-0d5b8187c834\",\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    conn.request(\"POST\", \"/sms/2/text/advanced\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    final = eval(data)\n",
    "    print(data)\n",
    "    print(final['bulkId'])\n",
    "\n",
    "    return final['bulkId']\n",
    "    \n",
    "# get secret function:\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            raise e\n",
    "    else:\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary']) \n",
    "\n",
    "# get message result:\n",
    "def get_sms_results(bulkId=None, messageId=None, after_timestamp=None):\n",
    "    # Authentication\n",
    "    conn = http.client.HTTPSConnection(\"qg3p63.api.infobip.com\")\n",
    "    payload = ''\n",
    "    headers = {\n",
    "        'Authorization': 'App b9c03ee856baa2b7ac96b4b0ecb8aa36-ce2dbf98-1fd2-4fff-9b8b-0d5b8187c834',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    # Get reports based on messageId:\n",
    "    if messageId:\n",
    "        # Connect with the API and get the response based on bulkId:\n",
    "        conn.request(\"GET\", \"/sms/1/logs?messageId={}\".format(messageId), payload, headers)\n",
    "        res = conn.getresponse()\n",
    "        data = res.read()\n",
    "        d = json.loads(data)\n",
    "        df = pd.DataFrame(d['results'])\n",
    "        new_col_names = [\n",
    "            'bulk_id',\n",
    "            'message_id',\n",
    "            'to',\n",
    "            'from',\n",
    "            'text',\n",
    "            'sent_at',\n",
    "            'done_at',\n",
    "            'sms_count',\n",
    "            'price',\n",
    "            'status',\n",
    "            'error',\n",
    "            'application_id'\n",
    "        ]\n",
    "\n",
    "        # data wrangling:\n",
    "        # error column cleaning\n",
    "        try:\n",
    "            df['error'] = df['error'].apply(lambda x: x['name'])\n",
    "\n",
    "            # status:\n",
    "            df['status'] = df['status'].apply(lambda x: x['groupName'])\n",
    "\n",
    "            # price:\n",
    "            df['price'] = df['price'].apply(lambda x: x['pricePerMessage'])\n",
    "\n",
    "            # dates cleaning:\n",
    "            df['sentAt'] = pd.to_datetime(df['sentAt'], format='%Y-%m-%dT%H:%M:%S').apply(lambda x: x.replace(tzinfo=None))\n",
    "            df['doneAt'] = pd.to_datetime(df['doneAt'], format='%Y-%m-%dT%H:%M:%S').apply(lambda x: x.replace(tzinfo=None))\n",
    "\n",
    "            # drop mccMnc:\n",
    "            df.drop(columns=['mccMnc'], inplace=True)\n",
    "\n",
    "            # drop the country code (2):\n",
    "            df.to = df.to.str[1:]\n",
    "\n",
    "            # change columns names:\n",
    "            df.columns = new_col_names\n",
    "\n",
    "        except Exception as e:\n",
    "            print('error e'.format(e))\n",
    "\n",
    "    # Get reports base on bulkId:\n",
    "    elif bulkId:\n",
    "        # Connect with the API and get the response based on bulkId:\n",
    "        conn.request(\"GET\", \"/sms/1/logs?bulkId={}\".format(bulkId), payload, headers)\n",
    "        res = conn.getresponse()\n",
    "        data = res.read()\n",
    "        d = json.loads(data)\n",
    "        df = pd.DataFrame(d['results'])\n",
    "        new_col_names = [\n",
    "            'bulk_id',\n",
    "            'message_id',\n",
    "            'to',\n",
    "            'from',\n",
    "            'text',\n",
    "            'sent_at',\n",
    "            'done_at',\n",
    "            'sms_count',\n",
    "            'price',\n",
    "            'status',\n",
    "            'error',\n",
    "            'application_id'\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # data wrangling:\n",
    "            # error column cleaning:\n",
    "            df['error'] = df['error'].apply(lambda x: x['name'])\n",
    "\n",
    "            # status:\n",
    "            df['status'] = df['status'].apply(lambda x: x['groupName'])\n",
    "\n",
    "            # price:\n",
    "            df['price'] = df['price'].apply(lambda x: x['pricePerMessage'])\n",
    "\n",
    "            # dates cleaning:\n",
    "            df['sentAt'] = pd.to_datetime(df['sentAt'], format='%Y-%m-%dT%H:%M:%S.%f%z').apply(lambda x: x.replace(tzinfo=None))\n",
    "            df['doneAt'] = pd.to_datetime(df['doneAt'], format='%Y-%m-%dT%H:%M:%S.%f%z').apply(lambda x: x.replace(tzinfo=None))\n",
    "\n",
    "            # drop mccMnc:\n",
    "            df.drop(columns=['mccMnc'], inplace=True)\n",
    "\n",
    "            # drop the country code (2):\n",
    "            df.to = df.to.str[1:]\n",
    "\n",
    "            # change columns names:\n",
    "            df.columns = new_col_names\n",
    "        except Exception as e:\n",
    "            print('error {}'.format(e))\n",
    "\n",
    "    else:\n",
    "        return print(\"error in inputs\")\n",
    "\n",
    "    if after_timestamp:\n",
    "        after_timestamp = datetime.datetime.strptime(after_timestamp, '%Y-%m-%d %H:%M:%S.%f')\n",
    "        df_subset = df.loc[df.sent_at >= after_timestamp]\n",
    "\n",
    "    else:\n",
    "        df_subset = df\n",
    "\n",
    "    return df_subset\n",
    "\n",
    "\n",
    "# def get_inputs_from_event (event, conn_r): \n",
    "    \n",
    "#     for record in event['Records']:\n",
    "#         data = record['dynamodb']['NewImage']\n",
    "#         print(data)\n",
    "#         print(event)\n",
    "    \n",
    "    \n",
    "#     linked_at_id = list(data['id'].values())[0]\n",
    "#     created_at = list(data['created_at'].values())[0]\n",
    "#     created_at = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "#     linked_at = created_at.date()\n",
    "#     retailer_id =  list(data['retailer_id'].values())[0]\n",
    "#     linked_device_id =  list(data['linked_device_id'].values())[0]\n",
    "    \n",
    "#     print(linked_at_id,created_at, linked_at, retailer_id, linked_device_id)\n",
    "    \n",
    "#     if(linked_at == datetime.today().date()):\n",
    "        \n",
    "#         print('linked today')\n",
    "        \n",
    "#         #get the linked device info \n",
    "    \n",
    "#         linked_device_info_sql = '''\n",
    "#         select device_type, device_manufacturer \n",
    "#         from emoney.linked_devices\n",
    "#         where id = {}\n",
    "#         '''.format(linked_device_id)\n",
    "        \n",
    "#         linked_device_info_sql_result = pd.read_sql(linked_device_info_sql, conn_r)\n",
    "#         device_type = linked_device_info_sql_result['device_type'][0]\n",
    "#         device_manufacturer = linked_device_info_sql_result['device_manufacturer'][0]\n",
    "        \n",
    "#         print(device_type, device_manufacturer)\n",
    "        \n",
    "#         #get the retailer mobile number \n",
    "        \n",
    "#         get_mobile_sql = '''\n",
    "#         select distinct r.main_system_id, r2.mobile \n",
    "#         from emoney.retailers r \n",
    "#         inner join public.retailers r2 on r.main_system_id=r2.id  \n",
    "#         where r.id = {}\n",
    "#         '''.format(retailer_id)\n",
    "        \n",
    "#         get_mobile_sql_result = pd.read_sql(get_mobile_sql, conn_r)\n",
    "#         main_system_id = get_mobile_sql_result['main_system_id'][0]\n",
    "#         mobile = get_mobile_sql_result['mobile'][0]\n",
    "        \n",
    "#         print(mobile)\n",
    "        \n",
    "#         return linked_at_id, retailer_id, linked_device_id, device_type, device_manufacturer, mobile \n",
    "#     else: \n",
    "#         return('invalid')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc5a39e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lambda_handler(event):\n",
    "    \n",
    "    # connect to the dwh db:\n",
    "    dwh_reader_secret_new = json.loads(get_secret(\"prod/db/datawarehouse/metabase\"))\n",
    "    dwh_writer_secret_new = json.loads(get_secret(\"prod/db/datawarehouse/sagemaker\"))\n",
    "\n",
    "    # get secrets: -dwh reader\n",
    "    host_r=dwh_reader_secret_new[\"host\"]\n",
    "    database_r=dwh_reader_secret_new[\"dbname\"]\n",
    "    user_r=dwh_reader_secret_new[\"username\"]\n",
    "    password_r=dwh_reader_secret_new[\"password\"]\n",
    "    \n",
    "    # get secrets: -dwh writer\n",
    "    host_w=dwh_writer_secret_new[\"host\"]\n",
    "    database_w=dwh_writer_secret_new[\"dbname\"]\n",
    "    user_w=dwh_writer_secret_new[\"username\"]\n",
    "    password_w=dwh_writer_secret_new[\"password\"]\n",
    "\n",
    "    conn_r = psycopg2.connect(host=host_r, database=database_r, user=user_r, password=password_r)\n",
    "    print(\"Successfully connected to reader DB\")\n",
    "    \n",
    "    conn_w = psycopg2.connect(host=host_w, database=database_w, user=user_w, password=password_w)\n",
    "    print(\"Successfully connected to writer DB\")\n",
    "    \n",
    "        \n",
    "#     # check if there is a need for the message:\n",
    "#     try:\n",
    "#         linked_at_id, retailer_id, linked_device_id, device_type, device_manufacturer, mobile  = get_inputs_from_event(event, conn_r)\n",
    "#         # get_inputs_from_event(event,conn_r)\n",
    "#     except Exception as e:\n",
    "#         print(\"error in getting full_result:{}\".format(e))\n",
    "#         check_validity = get_inputs_from_event(event, conn_r)\n",
    "    \n",
    "        \n",
    "    for record in event['Records']:\n",
    "        data = record['dynamodb']['NewImage']\n",
    "        print(data)\n",
    "        print(event)\n",
    "    \n",
    "    linked_at_id = list(data['id'].values())[0]\n",
    "    created_at = list(data['created_at'].values())[0]\n",
    "    linked_at = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    linked_at = linked_at.date()\n",
    "    retailer_id =  list(data['retailer_id'].values())[0]\n",
    "    linked_device_id = list(data['linked_device_id'].values())[0]\n",
    "    \n",
    "    if(linked_at != datetime.today().date()):\n",
    "        \n",
    "        print('device wasnt added today')\n",
    "        return('device wasnt added today')\n",
    "\n",
    "    #get the linked device info \n",
    "\n",
    "    linked_device_info_sql = '''\n",
    "    select device_type, device_manufacturer \n",
    "    from emoney.linked_devices\n",
    "    where id = {}\n",
    "    '''.format(linked_device_id)\n",
    "\n",
    "    linked_device_info_sql_result = pd.read_sql(linked_device_info_sql, conn_r)\n",
    "    device_type = linked_device_info_sql_result['device_type'][0]\n",
    "    device_manufacturer = linked_device_info_sql_result['device_manufacturer'][0]\n",
    "\n",
    "    #get the retailer mobile number \n",
    "\n",
    "    get_mobile_sql = '''\n",
    "    select distinct r.main_system_id, r2.mobile \n",
    "    from emoney.retailers r \n",
    "    inner join public.retailers r2 on r.main_system_id=r2.id  \n",
    "    where r.id = {}\n",
    "    '''.format(retailer_id)\n",
    "\n",
    "    get_mobile_sql_result = pd.read_sql(get_mobile_sql, conn_r)\n",
    "    main_system_id = get_mobile_sql_result['main_system_id'][0]\n",
    "    mobile = get_mobile_sql_result['mobile'][0]\n",
    "    \n",
    "    print(linked_at_id, linked_at, retailer_id, linked_device_id,mobile,main_system_id,device_type,device_manufacturer )\n",
    "  \n",
    "\n",
    "    #check if there is a need to send the sms \n",
    "    #check comms rules:\n",
    "    check_comm_counter_sql = '''\n",
    "     select distinct\n",
    "        receiver_id,\n",
    "        ref_entity,\n",
    "        ref_id,\n",
    "        receiver_phone,\n",
    "        date(cast(sending_time as date)) as sending_date,\n",
    "        count(case when message_status in ('PENDING','DELIVERED') then 1 else null end) over(partition by receiver_id, date_trunc('day',cast(sending_time as date))) as successful_sms_per_day,\n",
    "        count(*) over(partition by receiver_id, date_trunc('day',cast(sending_time as date))) as sms_per_day,\n",
    "        count(case when message_status in ('PENDING','DELIVERED') then 1 else null end) over(partition by receiver_id,ref_entity, ref_id) as successful_sms_per_entity_per_ref_id,\n",
    "        count(*) over(partition by receiver_id,ref_entity, ref_id) as sms_per_entity_per_ref_id\n",
    "    from fintech.fintech_communication_logs\n",
    "    where ref_entity = 'device_linked_at_id'\n",
    "        and communication_reason = 'new_device_notification_test'\n",
    "        and date(sending_time) = date(now()) \n",
    "        and ref_id = {}'''.format(linked_at_id)\n",
    "\n",
    "    try:\n",
    "        check_comm_counter_sql_result = pd.read_sql(check_comm_counter_sql, conn_r)\n",
    "        successful_sms_per_entity_per_ref_id = check_comm_counter_sql_result['successful_sms_per_entity_per_ref_id'][0]\n",
    "    except Exception as e:\n",
    "        print(\"error in comm counter result:{}\".format(e))\n",
    "        successful_sms_per_entity_per_ref_id = 0\n",
    "\n",
    "    if successful_sms_per_entity_per_ref_id >= 1:\n",
    "        print(\"message has already been sent\")\n",
    "        return \"max_comm_validation\"\n",
    "\n",
    "    \n",
    "    # Send SMS:\n",
    "    \n",
    "    # generate message object:\n",
    "#     receiver_mobile = \"2\"+mobile\n",
    "    receiver_mobile = \"201112255939\"\n",
    "\n",
    "    if device_type == 'MOBILE':\n",
    "        \n",
    "        sms_template = 'عميل مدفوعات، تم اضافة جهاز جديد {0} لحسابك. في حالة عدم الموافقة يرجى التواصل معنا على 15425 في اسرع وقت'\n",
    "        y = [{\n",
    "            'from':'MaxAB',\n",
    "            'destinations': [{\"to\": \"{}\".format(receiver_mobile)}], 'text': sms_template.format(device_manufacturer)}]\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        sms_template = 'عميل مدفوعات، تم اضافة ماكينة جديدة لحسابك. في حالة عدم الموافقة يرجى التواصل معنا على 15425 في اسرع وقت'\n",
    "        y = [{\n",
    "            'from':'MaxAB',\n",
    "            'destinations': [{\"to\": \"{}\".format(receiver_mobile)}], 'text': sms_template}]\n",
    "\n",
    "    message_tag = \"new_device_notification_{}\".format(linked_at_id)\n",
    "\n",
    "    send_message(y, tag=message_tag)\n",
    "    print('message_sent_to_{}'.format(linked_at_id))\n",
    "    time.sleep(20)\n",
    "\n",
    "    # get message result:\n",
    "    message_result = get_sms_results(bulkId=message_tag)\n",
    "    print(message_result)\n",
    "\n",
    "    try:\n",
    "        message_id = message_result[message_result.bulk_id == message_tag]['message_id'][0]\n",
    "    except:\n",
    "        message_id = 0\n",
    "    try:\n",
    "        sending_time = message_result[message_result.bulk_id == message_tag]['sent_at'][0]\n",
    "    except:\n",
    "        sending_time = datetime.now()\n",
    "    try:\n",
    "        message_status = message_result[message_result.bulk_id == message_tag]['status'][0]\n",
    "    except:\n",
    "        message_status = 'Unkown'\n",
    "\n",
    "\n",
    "    # Write SMS Logs to DB \n",
    "    # db connection:\n",
    "    \n",
    "    engine_w = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user_w}:{password_w}@{host_w}/{database_w}\")\n",
    "    print(bool(engine_w))\n",
    "    \n",
    "    with engine_w.connect() as conn:\n",
    "        print(\"start writing into fintech sms logs table\")\n",
    "        message_result.to_sql(name='fintech_sms_logs', schema='fintech', con=conn, if_exists='append', chunksize=1000, method='multi')\n",
    "        print(\"written into fintech sms logs table successfully\")\n",
    "\n",
    "    # push comm log to db\n",
    "    comm_df = pd.DataFrame(columns=[\n",
    "        'receiver_type',\n",
    "        'receiver_id',\n",
    "        'receiver_phone',\n",
    "        'communication_reason',\n",
    "        'ref_id',\n",
    "        'ref_entity',\n",
    "        'message_id',\n",
    "        'message_status',\n",
    "        'sending_time'])\n",
    "\n",
    "    comm_df.loc[len(comm_df)] = [\n",
    "        'retailer',\n",
    "        main_system_id,\n",
    "        mobile,\n",
    "        'new_device_notification_test',\n",
    "        linked_at_id,\n",
    "        'device_linked_at_id',\n",
    "        message_id,\n",
    "        message_status,\n",
    "        sending_time]\n",
    "\n",
    "    # update the table on db:\n",
    "    with engine_w.connect() as conn:\n",
    "        print(\"start writing into fintech communication logs table\")\n",
    "        comm_df.to_sql(\n",
    "            name='fintech_communication_logs',\n",
    "            schema='fintech',\n",
    "            con=conn,\n",
    "            if_exists='append',\n",
    "            chunksize=1000,\n",
    "            method='multi')\n",
    "        print(\"written into fintech communication logs table successfully\")\n",
    "\n",
    "\n",
    "\n",
    "    # close the connection:\n",
    "    conn_w.close()\n",
    "    conn_r.close()\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('Hello from Lambda!')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85175381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to reader DB\n",
      "Successfully connected to writer DB\n",
      "{'access_level': {'S': 'GENERAL'}, 'updated_at': {'S': '2024-05-26T2:16:11.832020Z'}, 'linked_device_id': {'N': '256034'}, 'created_at': {'S': '2024-05-26T2:16:11.832020Z'}, 'retailer_id': {'N': '877063'}, 'id': {'N': '123456789'}, 'retailer_linked_devices_ttl': {'N': '1716466571'}}\n",
      "{'Records': [{'eventID': 'ca1ef4007ec6fd6f5a60f4c28d78dccf', 'eventName': 'INSERT', 'eventVersion': '1.1', 'eventSource': 'aws:dynamodb', 'awsRegion': 'us-east-1', 'dynamodb': {'ApproximateCreationDateTime': 1716380172.0, 'Keys': {'id': {'N': '295131'}}, 'NewImage': {'access_level': {'S': 'GENERAL'}, 'updated_at': {'S': '2024-05-26T2:16:11.832020Z'}, 'linked_device_id': {'N': '256034'}, 'created_at': {'S': '2024-05-26T2:16:11.832020Z'}, 'retailer_id': {'N': '877063'}, 'id': {'N': '123456789'}, 'retailer_linked_devices_ttl': {'N': '1716466571'}}, 'SequenceNumber': '8989200000000069371723948', 'SizeBytes': 174, 'StreamViewType': 'NEW_IMAGE'}, 'eventSourceARN': 'arn:aws:dynamodb:us-east-1:876425898567:table/retailer_linked_devices/stream/2024-05-21T14:15:27.675'}]}\n",
      "123456789 2024-05-26 877063 256034 01112255939 391593 MOBILE OPPO\n",
      "message has already been sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18094/2629803145.py:60: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  linked_device_info_sql_result = pd.read_sql(linked_device_info_sql, conn_r)\n",
      "/tmp/ipykernel_18094/2629803145.py:73: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  get_mobile_sql_result = pd.read_sql(get_mobile_sql, conn_r)\n",
      "/tmp/ipykernel_18094/2629803145.py:100: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  check_comm_counter_sql_result = pd.read_sql(check_comm_counter_sql, conn_r)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'max_comm_validation'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_handler(\n",
    "    {\"Records\":[\n",
    "      {\n",
    "         \"eventID\":\"ca1ef4007ec6fd6f5a60f4c28d78dccf\",\n",
    "         \"eventName\":\"INSERT\",\n",
    "         \"eventVersion\":\"1.1\",\n",
    "         \"eventSource\":\"aws:dynamodb\",\n",
    "         \"awsRegion\":\"us-east-1\",\n",
    "         \"dynamodb\":{\n",
    "            \"ApproximateCreationDateTime\":1716380172.0,\n",
    "            \"Keys\":{\n",
    "               \"id\":{\n",
    "                  \"N\":\"295131\"\n",
    "               }\n",
    "            },\n",
    "            \"NewImage\":{\n",
    "               \"access_level\":{\n",
    "                  \"S\":\"GENERAL\"\n",
    "               },\n",
    "               \"updated_at\":{\n",
    "                  \"S\":\"2024-05-26T2:16:11.832020Z\"\n",
    "               },\n",
    "               \"linked_device_id\":{\n",
    "                  \"N\":\"256034\"\n",
    "               },\n",
    "               \"created_at\":{\n",
    "                  \"S\":\"2024-05-26T2:16:11.832020Z\"\n",
    "               },\n",
    "               \"retailer_id\":{\n",
    "                  \"N\":\"877063\"\n",
    "               },\n",
    "               \"id\":{\n",
    "                  \"N\":\"123456789\"\n",
    "               },\n",
    "               \"retailer_linked_devices_ttl\":{\n",
    "                  \"N\":\"1716466571\"\n",
    "               }\n",
    "            },\n",
    "            \"SequenceNumber\":\"8989200000000069371723948\",\n",
    "            \"SizeBytes\":174,\n",
    "            \"StreamViewType\":\"NEW_IMAGE\"\n",
    "         },\n",
    "         \"eventSourceARN\":\"arn:aws:dynamodb:us-east-1:876425898567:table/retailer_linked_devices/stream/2024-05-21T14:15:27.675\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3d094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
