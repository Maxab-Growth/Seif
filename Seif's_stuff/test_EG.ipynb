{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a13ecc0-e4d2-4bc7-a834-958607ee8100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gspread'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpsycopg2\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgspread\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytz\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gspread'"
     ]
    }
   ],
   "source": [
    "from common_functions import ret_metabase, google_sheets, dwh_query, upload_dataframe_to_pg\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import datetime as dt\n",
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import gspread\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94626539-e24e-4785-a532-31ec7b2449fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_available_agents(attendance_df, current_hour):\n",
    "    \"\"\"\n",
    "    Get a list of available task-based agents for the current hour based on attendance DataFrame.\n",
    "    Args:\n",
    "        attendance_df (pd.DataFrame): DataFrame with agent attendance info\n",
    "        current_hour (int): Current hour (24-hour format)\n",
    "    Returns:\n",
    "        list: List of available agent IDs\n",
    "    \"\"\"\n",
    "    attendance_copy = attendance_df.copy()\n",
    "    \n",
    "    attendance_copy['start_time'] = attendance_copy['start_time'].astype(int)\n",
    "    attendance_copy['end_time'] = attendance_copy['end_time'].astype(int)\n",
    "    \n",
    "    attendance_copy['assignment_start_time'] = attendance_copy['start_time'] - 1\n",
    "    attendance_copy['assignment_end_time'] = attendance_copy['end_time'] - 1\n",
    "    \n",
    "    attendance_copy['assign_data'] = np.where(\n",
    "        (current_hour >= attendance_copy['assignment_start_time']) & \n",
    "        (current_hour <= attendance_copy['assignment_end_time']),\n",
    "        'yes', 'no')\n",
    "    \n",
    "    task_based_agents = attendance_copy.loc[\n",
    "        (attendance_copy['project'] == 'task_based') & \n",
    "        (attendance_copy['assign_data'] == 'yes')]\n",
    "    \n",
    "    task_based_list = task_based_agents['agent_id'].values.tolist()\n",
    "    print(f\"Number of available agents: {len(task_based_list)}\")\n",
    "    return task_based_list\n",
    "def fetch_and_process_queries(query_ids, blacklisted_retailers):\n",
    "    \"\"\"\n",
    "    Fetch and process data from queries, removing blacklisted retailers and updating Google Sheets.\n",
    "    Args:\n",
    "        query_ids (pd.DataFrame): DataFrame with query IDs\n",
    "        blacklisted_retailers (list): List of blacklisted retailer IDs\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame of query results\n",
    "    \"\"\"\n",
    "    queries = query_ids['Task_based'].dropna().astype(int).tolist()\n",
    "    print(f\"Fetching data from {len(queries)} queries...\")\n",
    "    \n",
    "    # Process queries\n",
    "    dataframes = [ret_metabase(\"EGYPT\", query) for query in queries]\n",
    "    # print(dataframes)\n",
    "    empty_queries = []\n",
    "    for i, df in enumerate(dataframes):\n",
    "        if df.empty:\n",
    "            empty_queries.append(queries[i])\n",
    "        else:\n",
    "            print(f\"Query {queries[i]} returned {len(df)} records\")\n",
    "        df.columns = map(str.lower, df.columns)\n",
    "    if empty_queries:\n",
    "        print(f\"WARNING: Queries {empty_queries} returned empty dataframe!\")\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # write in google sheet available data\n",
    "    # ----------------------------------------\n",
    "    # check for empty queries and get project names\n",
    "    for idx, row in query_ids.iterrows():\n",
    "        query_id = row['Task_based']\n",
    "        if pd.notna(query_id):\n",
    "            df = ret_metabase(\"EGYPT\", int(query_id))\n",
    "            query_ids.at[idx, 'Available_data'] = 'Empty' if df.empty else str(len(df))\n",
    "            # Add project name if available\n",
    "            if not df.empty and 'PROJECT_NAME' in df.columns:\n",
    "                query_ids.at[idx, 'Project_Name'] = df['PROJECT_NAME'].iloc[0]\n",
    "\n",
    "    # Overwrite the sheet with updated full data\n",
    "    google_sheets('Agents - Retailers', 'Query ID', 'overwrite', df=query_ids)\n",
    "    \n",
    "    # Combine and clean dataframes\n",
    "    df_unfiltered = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"Total tasks available: {df_unfiltered.shape[0]}\")\n",
    "    \n",
    "    # Remove blacklisted retailers\n",
    "    df_raw = df_unfiltered[~df_unfiltered['main_system_id'].isin(blacklisted_retailers)]\n",
    "    df_raw = clean_column_id(df_raw, 'main_system_id')\n",
    "    print(f\"Removed {len(df_unfiltered) - len(df_raw)} blacklisted retailers\")\n",
    "    \n",
    "    return df_raw\n",
    "\n",
    "def assign_data_equal_projects(df, list):\n",
    "    \"\"\"\n",
    "    Distribute rows of a DataFrame equally among a list of agents, grouped by project name.\n",
    "    Special handling for credit projects: only agents 9191 and 5565 can be assigned to projects with 'credit' in the name.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'project_name'\n",
    "        list (list): List of agent IDs or names\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'agent_assigned' column\n",
    "    \"\"\"\n",
    "    df = df.sample(frac=1)  # Shuffle the data\n",
    "    project_types = df['project_name'].unique()\n",
    "    \n",
    "    # Define credit agents and other agents\n",
    "    credit_agents = [9191, 5565]\n",
    "    other_agents = [agent for agent in list if agent not in credit_agents]\n",
    "    \n",
    "    assigned_data = pd.DataFrame()\n",
    "    \n",
    "    for project in project_types:\n",
    "        project_df = df[df['project_name'] == project]\n",
    "        project_df = project_df.reset_index(drop=True)\n",
    "        \n",
    "        # Check if project contains 'credit' in the name (case insensitive)\n",
    "        is_credit_project = 'credit' in project.lower()\n",
    "        \n",
    "        if is_credit_project:\n",
    "            # For credit projects, only assign to credit agents\n",
    "            if len(credit_agents) > 0:\n",
    "                rows_per_agent = len(project_df) // len(credit_agents)\n",
    "                remainder = len(project_df) % len(credit_agents)\n",
    "                \n",
    "                # Distribute rows equally among credit agents\n",
    "                for i, agent in enumerate(credit_agents):\n",
    "                    start_idx = i * rows_per_agent\n",
    "                    end_idx = start_idx + rows_per_agent\n",
    "                    agent_data = project_df.iloc[start_idx:end_idx].copy()\n",
    "                    agent_data['agent_assigned'] = agent\n",
    "                    \n",
    "                    # Handle remainder\n",
    "                    if i < remainder:\n",
    "                        extra_row = project_df.iloc[end_idx:end_idx+1].copy()\n",
    "                        extra_row['agent_assigned'] = agent\n",
    "                        agent_data = pd.concat([agent_data, extra_row])\n",
    "                    \n",
    "                    assigned_data = pd.concat([assigned_data, agent_data])\n",
    "            else:\n",
    "                print(f\"Warning: No credit agents available for credit project '{project}'\")\n",
    "        else:\n",
    "            # For non-credit projects, assign to other agents only\n",
    "            if len(other_agents) > 0:\n",
    "                rows_per_agent = len(project_df) // len(other_agents)\n",
    "                remainder = len(project_df) % len(other_agents)\n",
    "                \n",
    "                # Distribute rows equally among other agents\n",
    "                for i, agent in enumerate(other_agents):\n",
    "                    start_idx = i * rows_per_agent\n",
    "                    end_idx = start_idx + rows_per_agent\n",
    "                    agent_data = project_df.iloc[start_idx:end_idx].copy()\n",
    "                    agent_data['agent_assigned'] = agent\n",
    "                    \n",
    "                    # Handle remainder\n",
    "                    if i < remainder:\n",
    "                        extra_row = project_df.iloc[end_idx:end_idx+1].copy()\n",
    "                        extra_row['agent_assigned'] = agent\n",
    "                        agent_data = pd.concat([agent_data, extra_row])\n",
    "                    \n",
    "                    assigned_data = pd.concat([assigned_data, agent_data])\n",
    "            else:\n",
    "                print(f\"Warning: No other agents available for non-credit project '{project}'\")\n",
    "    \n",
    "    assigned_data = assigned_data.reset_index(drop=True)\n",
    "    print(\"Assignment by project complete with credit project restrictions.\")\n",
    "    return assigned_data\n",
    "def clean_column_id(df, column_name):\n",
    "    \"\"\"\n",
    "    Clean a DataFrame column by removing commas and converting to integer type if possible.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to clean\n",
    "        column_name (str): Name of the column to clean\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned column\n",
    "    \"\"\"\n",
    "    # Ensure the column is treated as a string\n",
    "    df[column_name] = df[column_name].astype(str)\n",
    "    \n",
    "    # Replace commas in the string\n",
    "    df[column_name] = df[column_name].str.replace(',', '')\n",
    "    \n",
    "    # Convert back to an integer, if appropriate\n",
    "    df[column_name] = df[column_name].astype('Int64', errors='ignore')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cff096fc-5e25-4856-b192-bdae6f64cf01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n",
      "Number of available agents: 7\n",
      "/home/ec2-user/service_account_key.json\n",
      "Fetching data from 2 queries...\n",
      "/home/ec2-user/service_account_key.json\n",
      "/home/ec2-user/service_account_key.json\n",
      "Query 59703 returned 19227 records\n",
      "Query 62555 returned 4681 records\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7766/2367232811.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '19227' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  query_ids.at[idx, 'Available_data'] = 'Empty' if df.empty else str(len(df))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n",
      "/home/ec2-user/service_account_key.json\n",
      "Total tasks available: 23908\n",
      "Removed 0 blacklisted retailers\n",
      "Assignment by project complete with credit project restrictions.\n",
      "Assignment by project complete with credit project restrictions.\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now() + timedelta(hours=3)\n",
    "hour = int(str(now.time())[0:2])\n",
    "attendance = ret_metabase(\"EGYPT\", 13502)\n",
    "\n",
    "task_based_list = get_available_agents(attendance, hour)\n",
    "\n",
    "query_ids = google_sheets('Agents - Retailers', 'Query ID', 'get')\n",
    "blacklisted_retailers = query_ids['Blacklisted_retailers'].dropna().astype(int).tolist()\n",
    "data = fetch_and_process_queries(query_ids, blacklisted_retailers)\n",
    "\n",
    "unique_projects = data[\"project_name\"].unique()\n",
    "# Filter out projects with \"credit\" in the name for calculation\n",
    "projects_for_calculation = [proj for proj in unique_projects if 'credit' not in proj.lower()]\n",
    "no_task = int(((50*(len(task_based_list)-2))/len(projects_for_calculation))+2)\n",
    "final_data = []\n",
    "for i in unique_projects: \n",
    "    un_data = data[data['project_name'] == i]\n",
    "    # Skip the head filter for projects with \"credit\" in the name\n",
    "    if 'credit' not in i.lower():\n",
    "        un_data = un_data.head(no_task)\n",
    "    as_data = assign_data_equal_projects(un_data,task_based_list) \n",
    "    final_data.append(as_data)\n",
    "final_data = pd.concat(final_data, ignore_index=True)\n",
    "final_data = final_data.drop_duplicates(subset=[\"main_system_id\"], keep=\"first\")\n",
    "\n",
    "main_data = final_data.groupby('agent_assigned').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3a89c30-cbbc-4bd5-aef1-b1506ff684d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project_name</th>\n",
       "      <th>app acquisition</th>\n",
       "      <th>credit_project</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agent_assigned</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2484.0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648.0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280.0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8302.0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9191.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9785.0</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Difference</th>\n",
       "      <td>51</td>\n",
       "      <td>2341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "project_name    app acquisition  credit_project\n",
       "agent_assigned                                 \n",
       "2484.0                       51               0\n",
       "2648.0                       50               0\n",
       "5280.0                       50               0\n",
       "5565.0                        0            2339\n",
       "8302.0                       50               0\n",
       "9191.0                        0            2341\n",
       "9785.0                       49               0\n",
       "Difference                   51            2341"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot = final_data.pivot_table(\n",
    "    index=\"agent_assigned\",\n",
    "    columns=\"project_name\",\n",
    "    values=\"main_system_id\",   # or any column\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0\n",
    ")\n",
    "# Calculate the difference (max - min) for each project\n",
    "diff_row = pivot.max() - pivot.min()\n",
    "\n",
    "# Add it as a new row called \"Difference\"\n",
    "pivot.loc[\"Difference\"] = diff_row\n",
    "\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d3fa0-bb77-4411-a203-2fb063aedb5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
