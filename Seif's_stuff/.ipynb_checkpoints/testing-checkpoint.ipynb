{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d42b8b-df1e-46eb-b4bf-6065eb3fa5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from common_functions import google_sheets, get_secret, ret_metabase\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import sqlalchemy\n",
    "import requests\n",
    "import psycopg2\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47b31c6-2608-412e-be21-a47dd86197a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_env():\n",
    "    \"\"\"\n",
    "    Initialize environment variables and credentials for Snowflake, Slack, Metabase, and Google Sheets.\n",
    "    Reads secrets and sets them as environment variables for use in other functions.\n",
    "    \"\"\"\n",
    "    snowflake_sg_secret = json.loads(get_secret(\"Snowflake-sagemaker\"))\n",
    "    slack_secret = json.loads(get_secret(\"prod/slack/reports\"))\n",
    "    fintech_service_account = json.loads(get_secret(\"prod/fintechServiceEmail/credentials\"))\n",
    "    dwh_writer_secret = json.loads(get_secret(\"prod/db/datawarehouse/sagemaker\"))\n",
    "\n",
    "    os.environ[\"SNOWFLAKE_USERNAME\"] = snowflake_sg_secret[\"username\"]\n",
    "    os.environ[\"SNOWFLAKE_PASSWORD\"] = snowflake_sg_secret[\"password\"]\n",
    "    os.environ[\"SNOWFLAKE_ACCOUNT\"] = snowflake_sg_secret[\"account\"]\n",
    "    os.environ[\"SNOWFLAKE_DATABASE\"] = snowflake_sg_secret[\"database\"]\n",
    "\n",
    "    os.environ[\"SLACK_TOKEN\"] = slack_secret[\"token\"]\n",
    "\n",
    "    os.environ[\"FINTECH_EMONEY_EMAIL\"] = fintech_service_account[\"email_name\"]\n",
    "    os.environ[\"FINTECH_EMONEY_PASSWORD\"] = fintech_service_account[\"email_password\"]\n",
    "\n",
    "    metabase_secret = json.loads(get_secret(\"prod/metabase/maxab_config\"))\n",
    "    os.environ[\"EGYPT_METABASE_USERNAME\"] = metabase_secret[\"metabase_user\"]\n",
    "    os.environ[\"EGYPT_METABASE_PASSWORD\"] = metabase_secret[\"metabase_password\"]\n",
    "\n",
    "    os.environ[\"DWH_WRITER_HOST_NEW\"] = dwh_writer_secret[\"host\"]\n",
    "    os.environ[\"DWH_WRITER_NAME_NEW\"] = dwh_writer_secret[\"dbname\"]\n",
    "    os.environ[\"DWH_WRITER_USER_NAME_NEW\"] = dwh_writer_secret[\"username\"]\n",
    "    os.environ[\"DWH_WRITER_PASSWORD_NEW\"] = dwh_writer_secret[\"password\"] \n",
    "\n",
    "    json_path_sheets = str(Path.home()) + \"/service_account_key_sheets.json\"\n",
    "    sheets_key = get_secret(\"prod/maxab-sheets\")\n",
    "    f = open(json_path_sheets, \"w\")\n",
    "    f.write(sheets_key)\n",
    "    f.close()\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"] = json_path_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85986e4a-745e-4bea-9b7b-151864390868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_available_agents(attendance_df, current_hour):\n",
    "    \"\"\"\n",
    "    Get a list of available task-based agents for the current hour based on attendance DataFrame.\n",
    "    Args:\n",
    "        attendance_df (pd.DataFrame): DataFrame with agent attendance info\n",
    "        current_hour (int): Current hour (24-hour format)\n",
    "    Returns:\n",
    "        list: List of available agent IDs\n",
    "    \"\"\"\n",
    "    attendance_copy = attendance_df.copy()\n",
    "    \n",
    "    attendance_copy['start_time'] = attendance_copy['start_time'].astype(int)\n",
    "    attendance_copy['end_time'] = attendance_copy['end_time'].astype(int)\n",
    "    \n",
    "    attendance_copy['assignment_start_time'] = attendance_copy['start_time'] - 1\n",
    "    attendance_copy['assignment_end_time'] = attendance_copy['end_time'] - 1\n",
    "    \n",
    "    attendance_copy['assign_data'] = np.where(\n",
    "        (current_hour >= attendance_copy['assignment_start_time']) & \n",
    "        (current_hour <= attendance_copy['assignment_end_time']),\n",
    "        'yes', 'no')\n",
    "    \n",
    "    task_based_agents = attendance_copy.loc[\n",
    "        (attendance_copy['project'] == 'task_based') & \n",
    "        (attendance_copy['assign_data'] == 'yes')]\n",
    "    \n",
    "    task_based_list = task_based_agents['agent_id'].values.tolist()\n",
    "    print(f\"Number of available agents: {len(task_based_list)}\")\n",
    "    return task_based_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a222575d-5091-4426-b4d4-fb6cb6f659a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_data_equal_projects(df, list):\n",
    "    \"\"\"\n",
    "    Distribute rows of a DataFrame equally among a list of agents, grouped by project name.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'project_name'\n",
    "        list (list): List of agent IDs or names\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'agent_assigned' column\n",
    "    \"\"\"\n",
    "    df = df.sample(frac=1)  # Shuffle the data\n",
    "    project_types = df['project_name'].unique()\n",
    "    \n",
    "    assigned_data = pd.DataFrame()\n",
    "    \n",
    "    for project in project_types:\n",
    "        project_df = df[df['project_name'] == project]\n",
    "        project_df = project_df.reset_index(drop=True)\n",
    "        rows_per_agent = len(project_df) // len(list)\n",
    "        remainder = len(project_df) % len(list)\n",
    "        \n",
    "        # Distribute rows equally\n",
    "        for i, agent in enumerate(list):\n",
    "            start_idx = i * rows_per_agent\n",
    "            end_idx = start_idx + rows_per_agent\n",
    "            agent_data = project_df.iloc[start_idx:end_idx].copy()\n",
    "            agent_data['agent_assigned'] = agent\n",
    "            \n",
    "            # Handle remainder\n",
    "            if i < remainder:\n",
    "                extra_row = project_df.iloc[end_idx:end_idx+1].copy()\n",
    "                extra_row['agent_assigned'] = agent\n",
    "                agent_data = pd.concat([agent_data, extra_row])\n",
    "            \n",
    "            assigned_data = pd.concat([assigned_data, agent_data])\n",
    "    \n",
    "    assigned_data = assigned_data.reset_index(drop=True)\n",
    "    print(\"Assignment by project complete.\")\n",
    "    return assigned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0882082-448a-45e3-ae87-a8affdcb088c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    morocco_tz = pytz.timezone('Africa/Casablanca')\n",
    "    now = datetime.now(morocco_tz)\n",
    "    current_time = now.time()\n",
    "    current_day = now.strftime('%A')\n",
    "    print(current_day)\n",
    "    hour = int(str(now.time())[0:2])\n",
    "    hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3085a6b9-c2e7-4ee0-b5de-13793b5e2c52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RETAILER_ID</th>\n",
       "      <th>POLYGON_NAME_EN</th>\n",
       "      <th>MOBILE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LAST_ACTIVATION_DATE</th>\n",
       "      <th>LAST_ACTIVATION_DAY</th>\n",
       "      <th>PREV_ACTIVATION</th>\n",
       "      <th>PREV_ACT_DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94278</td>\n",
       "      <td>Iten_3</td>\n",
       "      <td>728107696</td>\n",
       "      <td>Prisca Koech</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22608</td>\n",
       "      <td>Jamhuri/Ayani/Karanja_2</td>\n",
       "      <td>710759483</td>\n",
       "      <td>shop Masai logwana</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106789</td>\n",
       "      <td>Kiganjo_1</td>\n",
       "      <td>711142128</td>\n",
       "      <td>Benson</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50976</td>\n",
       "      <td>Kamulu/Joska_4</td>\n",
       "      <td>724407810</td>\n",
       "      <td>hanna</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31616</td>\n",
       "      <td>Rimpa/Kiserian_1</td>\n",
       "      <td>722568784</td>\n",
       "      <td>Abdi Galgalo</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11942</th>\n",
       "      <td>178919</td>\n",
       "      <td>Kiriri/Kahawa wendani_3</td>\n",
       "      <td>743193353</td>\n",
       "      <td>Restoration shop</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11943</th>\n",
       "      <td>217271</td>\n",
       "      <td>Bul/Kerarapon/Karen_4</td>\n",
       "      <td>748361266</td>\n",
       "      <td>Reuben Gichana</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11944</th>\n",
       "      <td>193038</td>\n",
       "      <td>Lindi/Laini Saba/Uperhill_2</td>\n",
       "      <td>791526454</td>\n",
       "      <td>CATCHERS</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11945</th>\n",
       "      <td>134384</td>\n",
       "      <td>Bukura_1</td>\n",
       "      <td>725792435</td>\n",
       "      <td>joe</td>\n",
       "      <td>Kisumu</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>46472</td>\n",
       "      <td>Limuru_10</td>\n",
       "      <td>723845551</td>\n",
       "      <td>Grace Nganga</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11947 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RETAILER_ID              POLYGON_NAME_EN     MOBILE  \\\n",
       "0            94278                       Iten_3  728107696   \n",
       "1            22608      Jamhuri/Ayani/Karanja_2  710759483   \n",
       "2           106789                    Kiganjo_1  711142128   \n",
       "3            50976               Kamulu/Joska_4  724407810   \n",
       "4            31616             Rimpa/Kiserian_1  722568784   \n",
       "...            ...                          ...        ...   \n",
       "11942       178919      Kiriri/Kahawa wendani_3  743193353   \n",
       "11943       217271        Bul/Kerarapon/Karen_4  748361266   \n",
       "11944       193038  Lindi/Laini Saba/Uperhill_2  791526454   \n",
       "11945       134384                     Bukura_1  725792435   \n",
       "11946        46472                    Limuru_10  723845551   \n",
       "\n",
       "                     NAME     CITY LAST_ACTIVATION_DATE LAST_ACTIVATION_DAY  \\\n",
       "0            Prisca Koech  Eldoret           2025-07-01          2025-07-01   \n",
       "1      shop Masai logwana  Nairobi           2025-07-01          2025-07-03   \n",
       "2                  Benson  Nairobi           2025-07-01          2025-07-01   \n",
       "3                   hanna  Nairobi           2025-07-01          2025-07-10   \n",
       "4            Abdi Galgalo  Nairobi           2025-07-01          2025-07-11   \n",
       "...                   ...      ...                  ...                 ...   \n",
       "11942    Restoration shop  Nairobi           2025-07-01          2025-07-01   \n",
       "11943      Reuben Gichana  Nairobi           2025-07-01          2025-07-01   \n",
       "11944           CATCHERS   Nairobi           2025-07-01          2025-07-06   \n",
       "11945                 joe   Kisumu           2025-07-01          2025-07-02   \n",
       "11946        Grace Nganga  Nairobi           2025-07-01          2025-07-01   \n",
       "\n",
       "      PREV_ACTIVATION PREV_ACT_DAY  \n",
       "0          2025-06-01   2025-06-02  \n",
       "1          2025-06-01   2025-06-06  \n",
       "2          2025-06-01   2025-06-26  \n",
       "3          2025-06-01   2025-06-04  \n",
       "4          2025-06-01   2025-06-06  \n",
       "...               ...          ...  \n",
       "11942      2025-06-01   2025-06-11  \n",
       "11943      2025-06-01   2025-06-17  \n",
       "11944      2025-06-01   2025-06-01  \n",
       "11945      2025-06-01   2025-06-02  \n",
       "11946      2025-06-01   2025-06-01  \n",
       "\n",
       "[11947 rows x 9 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = ret_metabase(\"Kenya\",15328)\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed04533-8e0b-4089-b25b-d1c1584037c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = datetime.now() + timedelta(hours=3)\n",
    "hour = int(str(now.time())[0:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eec0a8b-2ce8-44d8-99b4-d24865f4fbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "Data = google_sheets(\"POS Campaign | July & August 2025\", \"Main\", \"Get\")\n",
    "# Convert Date column\n",
    "# Data[\"Date\"] = pd.to_datetime(Data[\"Date\"], format=\"%m/%d/%Y\")\n",
    "# # Get today's date (normalized to midnight)\n",
    "# today = pd.Timestamp.today().normalize()\n",
    "# # Filter for today's rows\n",
    "# Data_filtered = Data[Data[\"Date\"] == today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306e4d31-55b2-4344-a057-6cb8d01d3bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sheet_Data = Data.copy()\n",
    "sheet_Data.rename(columns={'mobile': 'main_system_id','name': 'retailer_name'},inplace=True)\n",
    "\n",
    "sheet_Data[\"main_system_id\"] = sheet_Data[\"main_system_id\"].astype('Int64').astype(str)\n",
    "sheet_Data[\"description\"] = (\n",
    "    \"POS Acquisition Marketing - location: \"\n",
    "    + sheet_Data[\"location\"].astype(str)\n",
    "    + \" - campaign:\"\n",
    "    + sheet_Data[\"campaign\"].astype(str)\n",
    ")\n",
    "\n",
    "\n",
    "sheet_Data.drop(columns=[\"location\", \"campaign\", \"Date\"], inplace=True)\n",
    "sheet_Data['Added_at'] = now\n",
    "sheet_Data['project_name'] = \"POS Leads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6bb74b14-9324-4a61-8cc5-c5093a48cf9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Date column\n",
    "Data[\"Date\"] = pd.to_datetime(Data[\"Date\"], format=\"%m/%d/%Y\")\n",
    "# Get today's date (normalized to midnight)\n",
    "today = pd.Timestamp.today().normalize()\n",
    "# Filter for today's rows\n",
    "filtered = Data[Data[\"Date\"] == today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6890acbc-7ba1-4a2f-b7df-a08a4bf59d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_list = [\n",
    " 'Somaya Alrab',\n",
    " 'Esraa Mohamed',\n",
    " 'Marina Riyad',\n",
    " 'Raneen Ali',\n",
    " 'Abdelrahman Merghany',\n",
    " 'Israa Abdelhamid',\n",
    " 'Nada Saber',\n",
    " 'Ebthal Saber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21baebc5-b4f6-440b-b5de-6f54c3f8d105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment by project complete.\n"
     ]
    }
   ],
   "source": [
    "Pos_leads = assign_data_equal_projects(sheet_Data , name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "905b2d31-e1d6-4b97-bd3f-9d0106b59cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "agent_group = google_sheets(\"Agents - Retailers\", \"Agent-to-group\", \"get\")\n",
    "col_list = agent_group.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6e1908-e5e8-4156-b126-17276b5e410a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data is appended to the sheet successfully'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_sheets(\"Agents - Retailers\", \"Task_based\", \"append\", df=Pos_leads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b9927f-1a7c-4f63-a3d8-5eb5540d62ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26988/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Somaya Alrab,51 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26988/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Esraa Mohamed,51 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26988/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Marina Riyad,51 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26988/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Raneen Ali,51 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26988/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Abdelrahman Merghany,51 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26988/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Israa Abdelhamid,51 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26988/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Nada Saber,50 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26988/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Ebthal Saber,50 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "for i in col_list:\n",
    "    if i == \"Benchmark\":\n",
    "        continue \n",
    "    filtered_df = Pos_leads[Pos_leads[\"agent_assigned\"] == i]\n",
    "    filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n",
    "    print(f\"Assigned to {i},{len(filtered_df)} Task-based Tasks\")\n",
    "    google_sheets(i, \"Task_based\", \"append\", df=filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d9724e-d035-4806-ba57-3fa013c2d8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "attendance = ret_metabase(\"EGYPT\", 13502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c085b89c-6bd0-4e0a-9f81-f5e8d480f43a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n",
      "Number of available agents: 8\n",
      "Assignment by project complete.\n",
      "Assignment by project complete.\n"
     ]
    }
   ],
   "source": [
    "Data = google_sheets(\"POS Campaign | July & August 2025\", \"Main\", \"Get\")\n",
    "\n",
    "task_based_list = get_available_agents(attendance, hour)\n",
    "# Convert Date column\n",
    "Data[\"Date\"] = pd.to_datetime(Data[\"Date\"], format=\"%m/%d/%Y\")\n",
    "# Get today's date (normalized to midnight)\n",
    "today = pd.Timestamp.today().normalize()\n",
    "# Filter for today's rows\n",
    "Data_filtered = Data[Data[\"Date\"] == today]\n",
    "\n",
    "sheet_Data = Data_filtered.copy()\n",
    "sheet_Data.rename(columns={'mobile': 'main_system_id','name': 'retailer_name'},inplace=True)\n",
    "\n",
    "sheet_Data[\"main_system_id\"] = sheet_Data[\"main_system_id\"].astype('Int64').astype(str)\n",
    "\n",
    "sheet_Data[\"description\"] = (\n",
    "    \"POS Acquisition Marketing - location: \"\n",
    "    + sheet_Data[\"location\"].astype(str)\n",
    "    + \" - campaign:\"\n",
    "    + sheet_Data[\"campaign\"].astype(str)\n",
    ")\n",
    "\n",
    "sheet_Data.drop(columns=[\"location\", \"campaign\", \"Date\"], inplace=True)\n",
    "sheet_Data['Added_at'] = now\n",
    "sheet_Data['project_name'] = \"POS Leads\"\n",
    "name_list = ['Somaya Alrab','Esraa Mohamed','Marina Riyad','Raneen Ali','Abdelrahman Merghany','Israa Abdelhamid','Nada Saber','Ebthal Saber']\n",
    "Pos_leads = assign_data_equal_projects(sheet_Data , name_list)\n",
    "data_for_sql = assign_data_equal_projects(sheet_Data, task_based_list)\n",
    "data_for_sql.rename(columns={'main_system_id': 'offer'},inplace=True)\n",
    "data_for_sql['main_system_id'] = 11111\n",
    "data_for_sql.drop(columns=[\"description\"], inplace=True)\n",
    "data_for_sql[\"description\"] = \"POS Acquisition Marketing - campaign: \" + Data[\"campaign\"]\n",
    "data_for_sql = data_for_sql[['main_system_id', 'description','offer','agent_assigned']]\n",
    "data_for_sql['dispatched_at'] = now\n",
    "data_for_sql['agent_assigned'] = data_for_sql['agent_assigned'].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78512b81-e617-474b-9652-87fbd3d6ee57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_system_id</th>\n",
       "      <th>description</th>\n",
       "      <th>offer</th>\n",
       "      <th>agent_assigned</th>\n",
       "      <th>dispatched_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201278771787</td>\n",
       "      <td>2484</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201116101363</td>\n",
       "      <td>2484</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201227725768</td>\n",
       "      <td>2484</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201224045696</td>\n",
       "      <td>2484</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201015495276</td>\n",
       "      <td>2484</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201011302096</td>\n",
       "      <td>5565</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201062284116</td>\n",
       "      <td>5565</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201100131329</td>\n",
       "      <td>5565</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201118588132</td>\n",
       "      <td>5565</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>11111</td>\n",
       "      <td>POS Acquisition Marketing - campaign: Delta</td>\n",
       "      <td>201279311477</td>\n",
       "      <td>5565</td>\n",
       "      <td>2025-07-16 13:37:21.712284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     main_system_id                                  description  \\\n",
       "0             11111  POS Acquisition Marketing - campaign: Delta   \n",
       "1             11111  POS Acquisition Marketing - campaign: Delta   \n",
       "2             11111  POS Acquisition Marketing - campaign: Delta   \n",
       "3             11111  POS Acquisition Marketing - campaign: Delta   \n",
       "4             11111  POS Acquisition Marketing - campaign: Delta   \n",
       "..              ...                                          ...   \n",
       "401           11111  POS Acquisition Marketing - campaign: Delta   \n",
       "402           11111  POS Acquisition Marketing - campaign: Delta   \n",
       "403           11111  POS Acquisition Marketing - campaign: Delta   \n",
       "404           11111  POS Acquisition Marketing - campaign: Delta   \n",
       "405           11111  POS Acquisition Marketing - campaign: Delta   \n",
       "\n",
       "            offer  agent_assigned              dispatched_at  \n",
       "0    201278771787            2484 2025-07-16 13:37:21.712284  \n",
       "1    201116101363            2484 2025-07-16 13:37:21.712284  \n",
       "2    201227725768            2484 2025-07-16 13:37:21.712284  \n",
       "3    201224045696            2484 2025-07-16 13:37:21.712284  \n",
       "4    201015495276            2484 2025-07-16 13:37:21.712284  \n",
       "..            ...             ...                        ...  \n",
       "401  201011302096            5565 2025-07-16 13:37:21.712284  \n",
       "402  201062284116            5565 2025-07-16 13:37:21.712284  \n",
       "403  201100131329            5565 2025-07-16 13:37:21.712284  \n",
       "404  201118588132            5565 2025-07-16 13:37:21.712284  \n",
       "405  201279311477            5565 2025-07-16 13:37:21.712284  \n",
       "\n",
       "[406 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66f3168-fe6f-406c-8e80-2b6387cfdd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_env():\n",
    "    \"\"\"\n",
    "    Initialize environment variables and credentials for Snowflake, Slack, Metabase, and Google Sheets.\n",
    "    Reads secrets and sets them as environment variables for use in other functions.\n",
    "    \"\"\"\n",
    "    snowflake_sg_secret = json.loads(get_secret(\"Snowflake-sagemaker\"))\n",
    "    slack_secret = json.loads(get_secret(\"prod/slack/reports\"))\n",
    "    fintech_service_account = json.loads(get_secret(\"prod/fintechServiceEmail/credentials\"))\n",
    "    dwh_writer_secret = json.loads(get_secret(\"prod/db/datawarehouse/sagemaker\"))\n",
    "\n",
    "    os.environ[\"SNOWFLAKE_USERNAME\"] = snowflake_sg_secret[\"username\"]\n",
    "    os.environ[\"SNOWFLAKE_PASSWORD\"] = snowflake_sg_secret[\"password\"]\n",
    "    os.environ[\"SNOWFLAKE_ACCOUNT\"] = snowflake_sg_secret[\"account\"]\n",
    "    os.environ[\"SNOWFLAKE_DATABASE\"] = snowflake_sg_secret[\"database\"]\n",
    "\n",
    "    os.environ[\"SLACK_TOKEN\"] = slack_secret[\"token\"]\n",
    "\n",
    "    os.environ[\"FINTECH_EMONEY_EMAIL\"] = fintech_service_account[\"email_name\"]\n",
    "    os.environ[\"FINTECH_EMONEY_PASSWORD\"] = fintech_service_account[\"email_password\"]\n",
    "\n",
    "    metabase_secret = json.loads(get_secret(\"prod/metabase/maxab_config\"))\n",
    "    os.environ[\"EGYPT_METABASE_USERNAME\"] = metabase_secret[\"metabase_user\"]\n",
    "    os.environ[\"EGYPT_METABASE_PASSWORD\"] = metabase_secret[\"metabase_password\"]\n",
    "\n",
    "    os.environ[\"DWH_WRITER_HOST_NEW\"] = dwh_writer_secret[\"host\"]\n",
    "    os.environ[\"DWH_WRITER_NAME_NEW\"] = dwh_writer_secret[\"dbname\"]\n",
    "    os.environ[\"DWH_WRITER_USER_NAME_NEW\"] = dwh_writer_secret[\"username\"]\n",
    "    os.environ[\"DWH_WRITER_PASSWORD_NEW\"] = dwh_writer_secret[\"password\"] \n",
    "\n",
    "    json_path_sheets = str(Path.home()) + \"/service_account_key_sheets.json\"\n",
    "    sheets_key = get_secret(\"prod/maxab-sheets\")\n",
    "    f = open(json_path_sheets, \"w\")\n",
    "    f.write(sheets_key)\n",
    "    f.close()\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_SHEETS\"] = json_path_sheets\n",
    "\n",
    "def send_text_slack(channel, text):\n",
    "    import slack\n",
    "    import os\n",
    "\n",
    "    initialize_env()\n",
    "\n",
    "    client = slack.WebClient(token=os.environ[\"SLACK_TOKEN\"])\n",
    "    try:\n",
    "        client.chat_postMessage(\n",
    "        channel=channel,\n",
    "        text=text\n",
    "      )\n",
    "        print('Message Sent')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "def task_fail_slack_alert(context):\n",
    "    slack_msg = \"\"\"\n",
    "        :red_circle: Task Failed.\n",
    "        *Task*: {task}  \n",
    "        *Dag*: {dag} \n",
    "        *Execution Time*: {exec_date}  \n",
    "        *Reason*: {exception}\n",
    "    \"\"\".format(\n",
    "        task=context.get('task_instance').task_id,\n",
    "        dag=context.get('task_instance').dag_id,\n",
    "        exec_date=context.get('execution_date'),\n",
    "        exception=context.get('exception')\n",
    "    )\n",
    "\n",
    "    send_text_slack(channel='account_mgmt_alerts', text=slack_msg)\n",
    "\n",
    "\n",
    "\n",
    "def clean_column_id(df, column_name):\n",
    "    \"\"\"\n",
    "    Clean a DataFrame column by removing commas and converting to integer type if possible.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to clean\n",
    "        column_name (str): Name of the column to clean\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned column\n",
    "    \"\"\"\n",
    "    # Ensure the column is treated as a string\n",
    "    df[column_name] = df[column_name].astype(str)\n",
    "    \n",
    "    # Replace commas in the string\n",
    "    df[column_name] = df[column_name].str.replace(',', '')\n",
    "    \n",
    "    # Convert back to an integer, if appropriate\n",
    "    df[column_name] = df[column_name].astype('Int64', errors='ignore')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ----------------------------------------\n",
    "# Mapping distribution (Segment-based)\n",
    "# ----------------------------------------\n",
    "def assign_data_by_mapping(df, mapping_df):\n",
    "    \"\"\"\n",
    "    Assign agents to retailers based on a mapping DataFrame.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'main_system_id'\n",
    "        mapping_df (pd.DataFrame): DataFrame with 'MAIN_SYSTEM_ID' and 'AGENT_ID'\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'agent_assigned' column\n",
    "    \"\"\"\n",
    "    # store retail-agent mapping in a dictionary \n",
    "    mapping_dict = dict(zip(mapping_df['MAIN_SYSTEM_ID'], mapping_df['AGENT_ID']))\n",
    "        \n",
    "    assigned_agents = []\n",
    "\n",
    "    for retailer_id in df['main_system_id']:\n",
    "        if retailer_id in mapping_dict:\n",
    "            assigned_agents.append(mapping_dict[retailer_id])\n",
    "        else:\n",
    "            assigned_agents.append(None)\n",
    "   \n",
    "    df['agent_assigned'] = assigned_agents\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def assign_data_equal_projects(df, list):\n",
    "    \"\"\"\n",
    "    Distribute rows of a DataFrame equally among a list of agents, grouped by project name.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'project_name'\n",
    "        list (list): List of agent IDs or names\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'agent_assigned' column\n",
    "    \"\"\"\n",
    "    df = df.sample(frac=1)  # Shuffle the data\n",
    "    project_types = df['project_name'].unique()\n",
    "    \n",
    "    assigned_data = pd.DataFrame()\n",
    "    \n",
    "    for project in project_types:\n",
    "        project_df = df[df['project_name'] == project]\n",
    "        project_df = project_df.reset_index(drop=True)\n",
    "        rows_per_agent = len(project_df) // len(list)\n",
    "        remainder = len(project_df) % len(list)\n",
    "        \n",
    "        # Distribute rows equally\n",
    "        for i, agent in enumerate(list):\n",
    "            start_idx = i * rows_per_agent\n",
    "            end_idx = start_idx + rows_per_agent\n",
    "            agent_data = project_df.iloc[start_idx:end_idx].copy()\n",
    "            agent_data['agent_assigned'] = agent\n",
    "            \n",
    "            # Handle remainder\n",
    "            if i < remainder:\n",
    "                extra_row = project_df.iloc[end_idx:end_idx+1].copy()\n",
    "                extra_row['agent_assigned'] = agent\n",
    "                agent_data = pd.concat([agent_data, extra_row])\n",
    "            \n",
    "            assigned_data = pd.concat([assigned_data, agent_data])\n",
    "    \n",
    "    assigned_data = assigned_data.reset_index(drop=True)\n",
    "    print(\"Assignment by project complete.\")\n",
    "    return assigned_data\n",
    "\n",
    "\n",
    "def get_available_agents(attendance_df, current_hour):\n",
    "    \"\"\"\n",
    "    Get a list of available task-based agents for the current hour based on attendance DataFrame.\n",
    "    Args:\n",
    "        attendance_df (pd.DataFrame): DataFrame with agent attendance info\n",
    "        current_hour (int): Current hour (24-hour format)\n",
    "    Returns:\n",
    "        list: List of available agent IDs\n",
    "    \"\"\"\n",
    "    attendance_copy = attendance_df.copy()\n",
    "    \n",
    "    attendance_copy['start_time'] = attendance_copy['start_time'].astype(int)\n",
    "    attendance_copy['end_time'] = attendance_copy['end_time'].astype(int)\n",
    "    \n",
    "    attendance_copy['assignment_start_time'] = attendance_copy['start_time'] - 1\n",
    "    attendance_copy['assignment_end_time'] = attendance_copy['end_time'] - 1\n",
    "    \n",
    "    attendance_copy['assign_data'] = np.where(\n",
    "        (current_hour >= attendance_copy['assignment_start_time']) & \n",
    "        (current_hour <= attendance_copy['assignment_end_time']),\n",
    "        'yes', 'no')\n",
    "    \n",
    "    task_based_agents = attendance_copy.loc[\n",
    "        (attendance_copy['project'] == 'task_based') & \n",
    "        (attendance_copy['assign_data'] == 'yes')]\n",
    "    \n",
    "    task_based_list = task_based_agents['agent_id'].values.tolist()\n",
    "    print(f\"Number of available agents: {len(task_based_list)}\")\n",
    "    return task_based_list\n",
    "\n",
    "\n",
    "def assign_offers(query_1, query_2, query_3=None):\n",
    "    \"\"\"\n",
    "    Assign offers from query_2 and query_3 to query_1 based on specific rules.\n",
    "    If a MAIN_SYSTEM_ID appears in both query_2 and query_3, assign one to OFFER_1 and one to OFFER_2.\n",
    "    \n",
    "    Args:\n",
    "        query_1 (pd.DataFrame): Main dataframe containing MAIN_SYSTEM_ID\n",
    "        query_2 (pd.DataFrame): Dataframe containing OFFER to be mapped as OFFER_1\n",
    "        query_3 (pd.DataFrame): Dataframe containing OFFER to be mapped as OFFER_2 or OFFER_1\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated query_1 with assigned offers\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    result = query_1.copy()\n",
    "    \n",
    "    # Ensure required columns exist in input dataframes\n",
    "    if 'MAIN_SYSTEM_ID' not in result.columns:\n",
    "        raise ValueError(\"query_1 must contain 'MAIN_SYSTEM_ID' column\")\n",
    "    if 'MAIN_SYSTEM_ID' not in query_2.columns or 'OFFER' not in query_2.columns:\n",
    "        raise ValueError(\"query_2 must contain 'MAIN_SYSTEM_ID' and 'OFFER' columns\")\n",
    "\n",
    "    \n",
    "    # Convert MAIN_SYSTEM_ID to string type in all dataframes\n",
    "    result['MAIN_SYSTEM_ID'] = result['MAIN_SYSTEM_ID'].astype(str)\n",
    "    query_2['MAIN_SYSTEM_ID'] = query_2['MAIN_SYSTEM_ID'].astype(str)\n",
    "\n",
    "    \n",
    "    # Step 1: Map query_2 offers to OFFER_1\n",
    "    # Create a new DataFrame with just the columns we need\n",
    "    offer1_df = pd.DataFrame({\n",
    "        'MAIN_SYSTEM_ID': query_2['MAIN_SYSTEM_ID'],\n",
    "        'OFFER_1_new': query_2['OFFER']  # Use a different name to avoid conflicts\n",
    "    })\n",
    "    \n",
    "    # Merge with result\n",
    "    result = pd.merge(result, offer1_df, on='MAIN_SYSTEM_ID', how='left')\n",
    "    print(\"\\nAfter first merge, columns:\", result.columns.tolist())\n",
    "\n",
    "    \n",
    "    if query_3 is not None:\n",
    "        if 'MAIN_SYSTEM_ID' not in query_3.columns or 'OFFER' not in query_3.columns:\n",
    "            raise ValueError(\"query_3 must contain 'MAIN_SYSTEM_ID' and 'OFFER' columns\")\n",
    "        query_3['MAIN_SYSTEM_ID'] = query_3['MAIN_SYSTEM_ID'].astype(str)\n",
    "        offer_temp_df = pd.DataFrame({\n",
    "            'MAIN_SYSTEM_ID': query_3['MAIN_SYSTEM_ID'],\n",
    "            'OFFER_temp': query_3['OFFER']\n",
    "        })\n",
    "        result = pd.merge(result, offer_temp_df, on='MAIN_SYSTEM_ID', how='left')\n",
    "        print(\"After second merge, columns:\", result.columns.tolist())\n",
    "\n",
    "        has_offer1 = result['OFFER_1'].notna() if 'OFFER_1' in result.columns else pd.Series([False]*len(result))\n",
    "        has_offer1_new = result['OFFER_1_new'].notna()\n",
    "        has_temp = result['OFFER_temp'].notna()\n",
    "\n",
    "        both_offers = has_offer1_new & has_temp\n",
    "        result.loc[both_offers, 'OFFER_1'] = result.loc[both_offers, 'OFFER_1_new']\n",
    "        result.loc[both_offers, 'OFFER_2'] = result.loc[both_offers, 'OFFER_temp']\n",
    "\n",
    "        result.loc[~has_offer1 & has_offer1_new & ~both_offers, 'OFFER_1'] = result.loc[~has_offer1 & has_offer1_new & ~both_offers, 'OFFER_1_new']\n",
    "        result.loc[~has_offer1 & has_temp & ~both_offers, 'OFFER_1'] = result.loc[~has_offer1 & has_temp & ~both_offers, 'OFFER_temp']\n",
    "        result.loc[has_offer1 & ~has_offer1_new & has_temp, 'OFFER_2'] = result.loc[has_offer1 & ~has_offer1_new & has_temp, 'OFFER_temp']\n",
    "\n",
    "        result.drop(columns=['OFFER_1_new', 'OFFER_temp'], inplace=True)\n",
    "    else:\n",
    "        # Only assign OFFER_1 from query_2\n",
    "        result['OFFER_1'] = result['OFFER_1_new']\n",
    "        if 'OFFER_1_new' in result.columns:\n",
    "            result.drop(columns=['OFFER_1_new'], inplace=True)\n",
    "    print(\"Final columns:\", result.columns.tolist())\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # query_1 = pd.DataFrame({'MAIN_SYSTEM_ID': [1, 2, 3]})\n",
    "    # query_2 = pd.DataFrame({'MAIN_SYSTEM_ID': [1, 2], 'OFFER': ['A', 'B']})\n",
    "    # query_3 = pd.DataFrame({'MAIN_SYSTEM_ID': [2, 3], 'OFFER': ['C', 'D']})\n",
    "    # result = assign_offers(query_1, query_2, query_3)\n",
    "    pass\n",
    "\n",
    "\n",
    "def assign_agents(new_data):\n",
    "    \"\"\"\n",
    "    Assign available agents to new data rows in a round-robin fashion.\n",
    "    Args:\n",
    "        new_data (pd.DataFrame): DataFrame of new leads or retailers\n",
    "    Returns:\n",
    "        np.ndarray: Array of assigned agent names\n",
    "    \"\"\"\n",
    "    Agents = google_sheets('Marketing test', 'Sheet2', 'get')\n",
    "    av_agents = Agents[Agents['Available'] == 'yes'].copy()\n",
    "    av_agents = av_agents[[\"Agent_assigned\"]]\n",
    "    agent_names = av_agents['Agent_assigned'].values\n",
    "    num_retailers = len(new_data)\n",
    "    repeated_agents = np.tile(agent_names, int(np.ceil(num_retailers / len(agent_names))))[:num_retailers]\n",
    "    np.random.shuffle(repeated_agents)\n",
    "    return repeated_agents\n",
    "\n",
    "def Add_marketing_leads():\n",
    "    \"\"\"\n",
    "    Process and add new marketing leads to the Google Sheet, assigning agents and cleaning data.\n",
    "    \"\"\"\n",
    "    pos_sheet = google_sheets('POS Leads', 'Master data', 'get')\n",
    "    pos_sheet_2 = google_sheets('POS Leads', 'Insurance data', 'get')\n",
    "\n",
    "\n",
    "    pos_sheet= pos_sheet[~pos_sheet['Mobile Number'].duplicated(keep=False)]\n",
    "\n",
    "    filtered_sheet = pos_sheet[\n",
    "        (~pos_sheet['Comment2'].str.lower().eq('done')) &\n",
    "        (~pos_sheet['Comment'].str.contains('done', case=False, na=False)) &\n",
    "        ((pos_sheet['المحافظة'].isin(['القاهره', 'الجيزة', 'giza'])) | (pos_sheet['المحافظة'].isna()))\n",
    "    ]\n",
    "\n",
    "\n",
    "    filtered_sheet = filtered_sheet.drop(['Call Status', 'Comment2', 'market type', 'Unnamed: 11', 'Unnamed: 12'], axis=1)\n",
    "\n",
    "    numbers_called = pos_sheet_2[\"Mobile Number\"].astype(str).str.extract(r'(\\d+)')[0].apply(lambda x: x.zfill(11))\n",
    "\n",
    "    new_data = filtered_sheet[~filtered_sheet['Mobile Number'].isin(numbers_called)]\n",
    "    new_data[['Description', 'Project Name']] = ['Insurance POS العميل طلب ماكينه تامين', 'Insurance POS']\n",
    "\n",
    "    new_data['Mobile Number'] = new_data['Mobile Number'].astype(str).apply(lambda x: '0' + x if not x.startswith('0') else x)\n",
    "\n",
    "    new_data[['Comment', 'Name']] = ''\n",
    "    agents = assign_agents(new_data)\n",
    "    new_data['Name'] = agents\n",
    "    # google_sheets('POS Leads', 'Insurance data', 'append', df = new_data)\n",
    "\n",
    "    print(f\"added {len(new_data)} new rows to the 'Insurance data' Sheet\")\n",
    "    \n",
    "    import re\n",
    "\n",
    "    # Remove any non-digit characters\n",
    "    new_data['Mobile Number'] = new_data['Mobile Number'].astype(str).apply(lambda x: re.sub(r'\\D', '', x))\n",
    "    \n",
    "    new_data_for_main = new_data.rename(columns={\n",
    "    'Name': 'agent_assigned',\n",
    "    'full_name': 'retailer_name',\n",
    "    'Project Name': 'project_name', \n",
    "    'Description' : 'description'\n",
    "    })[[\"agent_assigned\", \"retailer_name\", \"Mobile Number\", \"project_name\", 'description']]\n",
    "    \n",
    "    google_sheets(\"Agents - Retailers\", \"Task_based\", \"append\", df=new_data_for_main)\n",
    "    \n",
    "    \n",
    "def task_based():\n",
    "    \"\"\"\n",
    "    Main function to process and assign task-based projects to agents, update Google Sheets, and return main data.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of assigned tasks\n",
    "    \"\"\"\n",
    "    now = datetime.now() + timedelta(hours=3)\n",
    "    hour = int(str(now.time())[0:2])\n",
    "    \n",
    "    \n",
    "    attendance = ret_metabase(\"EGYPT\", 13502)\n",
    "\n",
    "    task_based_list = get_available_agents(attendance, hour)\n",
    "    \n",
    "    query_ids = google_sheets('Agents - Retailers', 'Query ID', 'get')\n",
    "    blacklisted_retailers = query_ids['Blacklisted_retailers'].dropna().astype(int).tolist()\n",
    "    data = fetch_and_process_queries(query_ids, blacklisted_retailers)\n",
    "    main_data = assign_data_equal_projects(data , task_based_list)\n",
    "\n",
    "    data_to_sql = main_data.copy()\n",
    "    \n",
    "    agents = google_sheets('Agents - Retailers', 'Data', 'get')\n",
    "\n",
    "    # Merge on agent ID\n",
    "    main_data = main_data.merge(agents, left_on='agent_assigned', right_on='Agent_id', how='left')\n",
    "\n",
    "    # Replace the agent_assigned column with the Agent name\n",
    "    main_data['agent_assigned'] = main_data['Agent']\n",
    "    \n",
    "    \n",
    "    # Optionally drop the now-redundant columns\n",
    "    main_data.drop(columns=['Agent', 'Agent_id'], inplace=True)\n",
    "    \n",
    "    main_data.drop(columns=[\"retailer_mobile_number\"], inplace=True, errors='ignore')\n",
    "    \n",
    "    main_data['Added_at'] = now\n",
    "    main_data = main_data[['agent_assigned', 'main_system_id', 'retailer_name', 'project_name', 'description', 'Added_at']]\n",
    "    print(f\" data before filtering {len(main_data)}\")\n",
    "    \n",
    "    data_dispatched = google_sheets(\"Agents - Retailers\", \"Task_based\", \"get\")\n",
    "    already_assigned_retailers = set(data_dispatched['main_system_id'].astype(int).unique())\n",
    "    main_data = main_data[~main_data['main_system_id'].isin(already_assigned_retailers)]\n",
    "    print(f\" data after filtering {len(main_data)}\")\n",
    "    main_data = main_data.groupby('agent_assigned').head(20)\n",
    "\n",
    "    # google_sheets(\"Agents - Retailers\", \"Task_based\", \"append\", df=main_data)\n",
    "    \n",
    "    print(\"tasks added to Task_based sheet\")\n",
    "    return main_data, data_to_sql\n",
    "    \n",
    "    \n",
    "def fetch_and_process_queries(query_ids, blacklisted_retailers):\n",
    "    \"\"\"\n",
    "    Fetch and process data from queries, removing blacklisted retailers and updating Google Sheets.\n",
    "    Args:\n",
    "        query_ids (pd.DataFrame): DataFrame with query IDs\n",
    "        blacklisted_retailers (list): List of blacklisted retailer IDs\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame of query results\n",
    "    \"\"\"\n",
    "    queries = query_ids['Task_based'].dropna().astype(int).tolist()\n",
    "    print(f\"Fetching data from {len(queries)} queries...\")\n",
    "    \n",
    "    # Process queries\n",
    "    dataframes = [ret_metabase(\"EGYPT\", query) for query in queries]\n",
    "    # print(dataframes)\n",
    "    empty_queries = []\n",
    "    for i, df in enumerate(dataframes):\n",
    "        if df.empty:\n",
    "            empty_queries.append(queries[i])\n",
    "        else:\n",
    "            print(f\"Query {queries[i]} returned {len(df)} records\")\n",
    "        df.columns = map(str.lower, df.columns)\n",
    "    if empty_queries:\n",
    "        print(f\"WARNING: Queries {empty_queries} returned empty dataframe!\")\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # write in google sheet available data\n",
    "    # ----------------------------------------\n",
    "    # check for empty queries and get project names\n",
    "    for idx, row in query_ids.iterrows():\n",
    "        query_id = row['Task_based']\n",
    "        if pd.notna(query_id):\n",
    "            df = ret_metabase(\"EGYPT\", int(query_id))\n",
    "            query_ids.at[idx, 'Available_data'] = 'Empty' if df.empty else str(len(df))\n",
    "            # Add project name if available\n",
    "            if not df.empty and 'PROJECT_NAME' in df.columns:\n",
    "                query_ids.at[idx, 'Project_Name'] = df['PROJECT_NAME'].iloc[0]\n",
    "\n",
    "    # Overwrite the sheet with updated full data\n",
    "    google_sheets('Agents - Retailers', 'Query ID', 'overwrite', df=query_ids)\n",
    "    \n",
    "    # Combine and clean dataframes\n",
    "    df_unfiltered = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"Total tasks available: {df_unfiltered.shape[0]}\")\n",
    "    \n",
    "    # Remove blacklisted retailers\n",
    "    df_raw = df_unfiltered[~df_unfiltered['main_system_id'].isin(blacklisted_retailers)]\n",
    "    df_raw = clean_column_id(df_raw, 'main_system_id')\n",
    "    print(f\"Removed {len(df_unfiltered) - len(df_raw)} blacklisted retailers\")\n",
    "    \n",
    "    return df_raw\n",
    "\n",
    "\n",
    "def ranking_system(query):\n",
    "    \"\"\"\n",
    "    Reorder a DataFrame of calls by recency and rank, prioritizing older calls and those with offers.\n",
    "    Args:\n",
    "        query (pd.DataFrame): DataFrame with call and offer info\n",
    "    Returns:\n",
    "        pd.DataFrame: Reordered DataFrame\n",
    "    \"\"\"\n",
    "    # Convert the LAST_REACHABLE_CALL column to datetime\n",
    "    query['LAST_REACHABLE_CALL'] = pd.to_datetime(query['LAST_REACHABLE_CALL'])\n",
    "\n",
    "    # Calculate the cutoff date for recent calls\n",
    "    now = datetime.now()\n",
    "    five_days_ago = now - timedelta(days=5)\n",
    "\n",
    "    # Separate into recent and older calls\n",
    "    recent_calls = query[query['LAST_REACHABLE_CALL'] >= five_days_ago].copy()\n",
    "    older_calls = query[(query['LAST_REACHABLE_CALL'] < five_days_ago) | (query[\"LAST_REACHABLE_CALL\"].isnull())].copy()\n",
    "\n",
    "    offer = older_calls[older_calls['OFFER_1'].notnull()].copy()\n",
    "    no_offer = older_calls[older_calls['OFFER_1'].isnull()].copy()\n",
    "    # Sort both by RANK\n",
    "    offer.sort_values(by=\"RANK\", ascending=True, inplace=True)\n",
    "    no_offer.sort_values(by=\"RANK\", ascending=True, inplace=True)\n",
    "    recent_calls.sort_values(by=\"RANK\", ascending=True, inplace=True)\n",
    "\n",
    "    # Combine: older calls first, then recent ones\n",
    "    reordered_df = pd.concat([offer, no_offer, recent_calls], ignore_index=True)\n",
    "\n",
    "\n",
    "    \n",
    "    return reordered_df\n",
    "initialize_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec14693-e28b-4a4c-b88b-15dd2b2b9fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent dispatching process...\n",
      "/home/ec2-user/service_account_key.json\n",
      "/home/ec2-user/service_account_key.json\n",
      "/home/ec2-user/service_account_key.json\n",
      "/home/ec2-user/service_account_key.json\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting agent dispatching process...\")\n",
    "query_1 = ret_metabase(\"Egypt\", 60949)\n",
    "query_2 = ret_metabase(\"Egypt\", 61071)\n",
    "query_3 = ret_metabase(\"Egypt\", 61188)\n",
    "sheet_data = google_sheets(\"Agents - Retailers\", \"raw_data\", \"get\")\n",
    "agent_group = google_sheets(\"Agents - Retailers\", \"Agent-to-group\", \"get\")\n",
    "col_list = agent_group.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725bcece-fab9-492e-89e0-8c437bee39eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "attendance = ret_metabase(\"EGYPT\", 13502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b45d3dfa-c0b9-41c5-9ea8-1b0c1b39b4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n",
      "Number of available agents: 8\n",
      "Assignment by project complete.\n",
      "Assignment by project complete.\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14753/3729423409.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Somaya Alrab,9 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14753/3729423409.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Esraa Mohamed,9 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14753/3729423409.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Marina Riyad,9 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14753/3729423409.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Raneen Ali,8 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14753/3729423409.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Abdelrahman Merghany,8 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14753/3729423409.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Israa Abdelhamid,8 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14753/3729423409.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Nada Saber,8 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14753/3729423409.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Ebthal Saber,8 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "Data = google_sheets(\"POS Campaign | July & August 2025\", \"Main\", \"Get\")\n",
    "\n",
    "task_based_list = get_available_agents(attendance, hour)\n",
    "# Convert Date column\n",
    "Data[\"Date\"] = pd.to_datetime(Data[\"Date\"], format=\"%m/%d/%Y\")\n",
    "# Get today's date (normalized to midnight)\n",
    "today = pd.Timestamp.today().normalize()\n",
    "# Filter for today's rows\n",
    "Data_filtered = Data[Data[\"Date\"] == today]\n",
    "\n",
    "sheet_Data = Data_filtered.copy()\n",
    "sheet_Data.rename(columns={'mobile': 'main_system_id','name': 'retailer_name'},inplace=True)\n",
    "\n",
    "sheet_Data[\"main_system_id\"] = sheet_Data[\"main_system_id\"].astype('Int64').astype(str)\n",
    "# Remove leading '2' if present\n",
    "sheet_Data[\"main_system_id\"] = sheet_Data[\"main_system_id\"].str.replace(r\"^2\", \"\", regex=True)\n",
    "\n",
    "# Drop duplicate main_system_id values (keeping first occurrence)\n",
    "sheet_Data = sheet_Data.drop_duplicates(subset=\"main_system_id\", keep=\"first\")\n",
    "\n",
    "sheet_Data[\"description\"] = (\n",
    "    \"POS Acquisition Marketing - location: \"\n",
    "    + sheet_Data[\"location\"].astype(str)\n",
    "    + \" - campaign:\"\n",
    "    + sheet_Data[\"campaign\"].astype(str)\n",
    ")\n",
    "\n",
    "sheet_Data.drop(columns=[\"location\", \"campaign\", \"Date\"], inplace=True)\n",
    "sheet_Data['Added_at'] = now\n",
    "sheet_Data['project_name'] = \"POS Leads\"\n",
    "name_list = ['Somaya Alrab','Esraa Mohamed','Marina Riyad','Raneen Ali','Abdelrahman Merghany','Israa Abdelhamid','Nada Saber','Ebthal Saber']\n",
    "Pos_leads = assign_data_equal_projects(sheet_Data , name_list)\n",
    "data_for_sql = assign_data_equal_projects(sheet_Data, task_based_list)\n",
    "data_for_sql.rename(columns={'main_system_id': 'offer'},inplace=True)\n",
    "data_for_sql['main_system_id'] = 11111\n",
    "data_for_sql.drop(columns=[\"description\"], inplace=True)\n",
    "data_for_sql[\"description\"] = \"POS Acquisition Marketing - campaign: \" + Data[\"campaign\"]\n",
    "data_for_sql = data_for_sql[['main_system_id', 'description','offer','agent_assigned']]\n",
    "data_for_sql['dispatched_at'] = now\n",
    "data_for_sql['agent_assigned'] = data_for_sql['agent_assigned'].astype(int) \n",
    "google_sheets(\"Agents - Retailers\", \"Task_based\", \"append\", df=Pos_leads)\n",
    "\n",
    "for i in col_list:\n",
    "    if i == \"Benchmark\":\n",
    "        continue \n",
    "    filtered_df = Pos_leads[Pos_leads[\"agent_assigned\"] == i]\n",
    "    filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n",
    "    print(f\"Assigned to {i},{len(filtered_df)} Task-based Tasks\")\n",
    "    google_sheets(i, \"Task_based\", \"append\", df=filtered_df)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    data_for_sql.to_sql('task_based_am_projects', schema='fintech', con=engine, if_exists='append', chunksize=1000, method='multi', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe16fecf-4c71-49cb-ad85-59132c388360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "query_1 = ret_metabase(\"Egypt\", 60949)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d60cd9d-8df9-4645-8792-a7146146a78c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T5' 'C1' 'T1' 'T4' 'T3' 'T6' 'T2' 'T7']\n"
     ]
    }
   ],
   "source": [
    "unique_group_types = query_1['GROUP_TYPE'].unique()\n",
    "print(unique_group_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e318840-603f-43a6-a696-99426e24b35f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to DB\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "    initialize_env()\n",
    "\n",
    "    host = os.environ[\"DWH_WRITER_HOST_NEW\"]\n",
    "    database = os.environ[\"DWH_WRITER_NAME_NEW\"]\n",
    "    user = os.environ[\"DWH_WRITER_USER_NAME_NEW\"]\n",
    "    password = os.environ[\"DWH_WRITER_PASSWORD_NEW\"]\n",
    "\n",
    "    conn = psycopg2.connect(host=host, database=database, user=user, password=password)\n",
    "    print(\"Successfully connected to DB\")\n",
    "    \n",
    "    # db connection:\n",
    "    engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}/{database}\")\n",
    "    print(bool(engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bcad80c-8c1b-4a7f-8765-b9657a4a447e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    data_for_sql.to_sql('task_based_am_projects', schema='fintech', con=engine, if_exists='append', chunksize=1000, method='multi', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c986a9d3-97fc-4fc6-8e9f-8dae60b1e57f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8250/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Somaya Alrab,18 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8250/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Esraa Mohamed,17 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8250/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Marina Riyad,17 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8250/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Raneen Ali,17 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8250/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Abdelrahman Merghany,16 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8250/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Israa Abdelhamid,17 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8250/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Nada Saber,17 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8250/3028924703.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned to Ebthal Saber,17 Task-based Tasks\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "for i in col_list:\n",
    "    if i == \"Benchmark\":\n",
    "        continue \n",
    "    filtered_df = Pos_leads[Pos_leads[\"agent_assigned\"] == i]\n",
    "    filtered_df.drop(columns=[\"agent_assigned\"], inplace=True)\n",
    "    print(f\"Assigned to {i},{len(filtered_df)} Task-based Tasks\")\n",
    "    google_sheets(i, \"Task_based\", \"append\", df=filtered_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
